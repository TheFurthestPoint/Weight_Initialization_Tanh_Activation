{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a95b5cd-39fc-4f64-9fa1-97fcc641ec01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "938/938 [==============================] - 65s 65ms/step - loss: 2.3023 - accuracy: 0.1070 - val_loss: 2.3022 - val_accuracy: 0.1135\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 59s 62ms/step - loss: 2.3019 - accuracy: 0.1124 - val_loss: 2.3019 - val_accuracy: 0.1135\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.3016 - accuracy: 0.1124 - val_loss: 2.3017 - val_accuracy: 0.1135\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 59s 63ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 59s 63ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 59s 63ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.2721 - accuracy: 0.1443 - val_loss: 2.1898 - val_accuracy: 0.2455\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.0974 - accuracy: 0.2947 - val_loss: 2.0117 - val_accuracy: 0.3313\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.9355 - accuracy: 0.3651 - val_loss: 1.8586 - val_accuracy: 0.3996\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.8029 - accuracy: 0.4179 - val_loss: 1.7451 - val_accuracy: 0.4412\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.6985 - accuracy: 0.4592 - val_loss: 1.6520 - val_accuracy: 0.4715\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.6178 - accuracy: 0.4807 - val_loss: 1.5717 - val_accuracy: 0.4944\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.5551 - accuracy: 0.4932 - val_loss: 1.5252 - val_accuracy: 0.4916\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.5008 - accuracy: 0.5052 - val_loss: 1.4648 - val_accuracy: 0.5141\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.4520 - accuracy: 0.5216 - val_loss: 1.4254 - val_accuracy: 0.5343\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.4144 - accuracy: 0.5353 - val_loss: 1.3838 - val_accuracy: 0.5435\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.3849 - accuracy: 0.5426 - val_loss: 1.3538 - val_accuracy: 0.5525\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.3602 - accuracy: 0.5481 - val_loss: 1.3375 - val_accuracy: 0.5568\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.3354 - accuracy: 0.5553 - val_loss: 1.3190 - val_accuracy: 0.5593\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.3198 - accuracy: 0.5577 - val_loss: 1.2942 - val_accuracy: 0.5723\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.3001 - accuracy: 0.5639 - val_loss: 1.2720 - val_accuracy: 0.5762\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.2840 - accuracy: 0.5706 - val_loss: 1.2641 - val_accuracy: 0.5790\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.2737 - accuracy: 0.5757 - val_loss: 1.2456 - val_accuracy: 0.5910\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.2612 - accuracy: 0.5823 - val_loss: 1.2368 - val_accuracy: 0.5954\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.2507 - accuracy: 0.5907 - val_loss: 1.2258 - val_accuracy: 0.6029\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.2446 - accuracy: 0.5913 - val_loss: 1.2255 - val_accuracy: 0.6082\n",
      "Epoch 38/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.2344 - accuracy: 0.5950 - val_loss: 1.2093 - val_accuracy: 0.6076\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.2254 - accuracy: 0.5975 - val_loss: 1.2004 - val_accuracy: 0.6112\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 1.2190 - accuracy: 0.5992 - val_loss: 1.1950 - val_accuracy: 0.6121\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.2119 - accuracy: 0.6014 - val_loss: 1.1914 - val_accuracy: 0.6165\n",
      "Epoch 42/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.2078 - accuracy: 0.6024 - val_loss: 1.1831 - val_accuracy: 0.6171\n",
      "Epoch 43/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.2018 - accuracy: 0.6051 - val_loss: 1.1807 - val_accuracy: 0.6174\n",
      "Epoch 44/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1984 - accuracy: 0.6059 - val_loss: 1.1744 - val_accuracy: 0.6202\n",
      "Epoch 45/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1977 - accuracy: 0.6064 - val_loss: 1.1885 - val_accuracy: 0.6070\n",
      "Epoch 46/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.2073 - accuracy: 0.6014 - val_loss: 1.1911 - val_accuracy: 0.6059\n",
      "Epoch 47/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.2045 - accuracy: 0.6021 - val_loss: 1.1855 - val_accuracy: 0.6097\n",
      "Epoch 48/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1919 - accuracy: 0.6077 - val_loss: 1.1701 - val_accuracy: 0.6164\n",
      "Epoch 49/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1817 - accuracy: 0.6114 - val_loss: 1.1598 - val_accuracy: 0.6226\n",
      "Epoch 50/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1787 - accuracy: 0.6115 - val_loss: 1.1569 - val_accuracy: 0.6238\n",
      "Epoch 51/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1810 - accuracy: 0.6105 - val_loss: 1.1580 - val_accuracy: 0.6270\n",
      "Epoch 52/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1728 - accuracy: 0.6128 - val_loss: 1.1517 - val_accuracy: 0.6246\n",
      "Epoch 53/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1704 - accuracy: 0.6140 - val_loss: 1.1462 - val_accuracy: 0.6268\n",
      "Epoch 54/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1669 - accuracy: 0.6160 - val_loss: 1.1440 - val_accuracy: 0.6273\n",
      "Epoch 55/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1653 - accuracy: 0.6166 - val_loss: 1.1435 - val_accuracy: 0.6275\n",
      "Epoch 56/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1616 - accuracy: 0.6171 - val_loss: 1.1388 - val_accuracy: 0.6293\n",
      "Epoch 57/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1612 - accuracy: 0.6177 - val_loss: 1.1432 - val_accuracy: 0.6270\n",
      "Epoch 58/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1651 - accuracy: 0.6160 - val_loss: 1.1462 - val_accuracy: 0.6248\n",
      "Epoch 59/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1623 - accuracy: 0.6179 - val_loss: 1.1434 - val_accuracy: 0.6269\n",
      "Epoch 60/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1566 - accuracy: 0.6195 - val_loss: 1.1334 - val_accuracy: 0.6295\n",
      "Epoch 61/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1568 - accuracy: 0.6189 - val_loss: 1.1386 - val_accuracy: 0.6283\n",
      "Epoch 62/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1539 - accuracy: 0.6210 - val_loss: 1.1274 - val_accuracy: 0.6343\n",
      "Epoch 63/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1481 - accuracy: 0.6232 - val_loss: 1.1248 - val_accuracy: 0.6352\n",
      "Epoch 64/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1457 - accuracy: 0.6233 - val_loss: 1.1253 - val_accuracy: 0.6349\n",
      "Epoch 65/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1454 - accuracy: 0.6242 - val_loss: 1.1223 - val_accuracy: 0.6374\n",
      "Epoch 66/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1430 - accuracy: 0.6251 - val_loss: 1.1175 - val_accuracy: 0.6400\n",
      "Epoch 67/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1409 - accuracy: 0.6253 - val_loss: 1.1184 - val_accuracy: 0.6375\n",
      "Epoch 68/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 1.1400 - accuracy: 0.6253 - val_loss: 1.1166 - val_accuracy: 0.6373\n",
      "Epoch 69/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1439 - accuracy: 0.6240 - val_loss: 1.1233 - val_accuracy: 0.6376\n",
      "Epoch 70/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 1.1445 - accuracy: 0.6238 - val_loss: 1.1210 - val_accuracy: 0.6385\n",
      "Epoch 71/100\n",
      "938/938 [==============================] - 61s 66ms/step - loss: 1.1458 - accuracy: 0.6231 - val_loss: 1.1143 - val_accuracy: 0.6394\n",
      "Epoch 72/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1407 - accuracy: 0.6255 - val_loss: 1.1126 - val_accuracy: 0.6395\n",
      "Epoch 73/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1424 - accuracy: 0.6256 - val_loss: 1.1223 - val_accuracy: 0.6391\n",
      "Epoch 74/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1360 - accuracy: 0.6260 - val_loss: 1.1126 - val_accuracy: 0.6401\n",
      "Epoch 75/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1338 - accuracy: 0.6272 - val_loss: 1.1111 - val_accuracy: 0.6388\n",
      "Epoch 76/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1331 - accuracy: 0.6273 - val_loss: 1.1111 - val_accuracy: 0.6389\n",
      "Epoch 77/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1308 - accuracy: 0.6282 - val_loss: 1.1073 - val_accuracy: 0.6393\n",
      "Epoch 78/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1287 - accuracy: 0.6284 - val_loss: 1.1115 - val_accuracy: 0.6394\n",
      "Epoch 79/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1334 - accuracy: 0.6262 - val_loss: 1.1126 - val_accuracy: 0.6370\n",
      "Epoch 80/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1360 - accuracy: 0.6259 - val_loss: 1.1204 - val_accuracy: 0.6339\n",
      "Epoch 81/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1390 - accuracy: 0.6243 - val_loss: 1.1208 - val_accuracy: 0.6332\n",
      "Epoch 82/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1400 - accuracy: 0.6226 - val_loss: 1.1247 - val_accuracy: 0.6317\n",
      "Epoch 83/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1345 - accuracy: 0.6257 - val_loss: 1.1095 - val_accuracy: 0.6373\n",
      "Epoch 84/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1278 - accuracy: 0.6278 - val_loss: 1.1040 - val_accuracy: 0.6379\n",
      "Epoch 85/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1247 - accuracy: 0.6292 - val_loss: 1.1068 - val_accuracy: 0.6391\n",
      "Epoch 86/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1268 - accuracy: 0.6273 - val_loss: 1.1065 - val_accuracy: 0.6380\n",
      "Epoch 87/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1278 - accuracy: 0.6281 - val_loss: 1.1124 - val_accuracy: 0.6350\n",
      "Epoch 88/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1322 - accuracy: 0.6254 - val_loss: 1.1113 - val_accuracy: 0.6349\n",
      "Epoch 89/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1256 - accuracy: 0.6283 - val_loss: 1.1038 - val_accuracy: 0.6394\n",
      "Epoch 90/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1253 - accuracy: 0.6282 - val_loss: 1.1064 - val_accuracy: 0.6375\n",
      "Epoch 91/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1252 - accuracy: 0.6281 - val_loss: 1.1014 - val_accuracy: 0.6393\n",
      "Epoch 92/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1271 - accuracy: 0.6272 - val_loss: 1.1049 - val_accuracy: 0.6383\n",
      "Epoch 93/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1250 - accuracy: 0.6278 - val_loss: 1.1086 - val_accuracy: 0.6367\n",
      "Epoch 94/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 1.1240 - accuracy: 0.6284 - val_loss: 1.1029 - val_accuracy: 0.6398\n",
      "Epoch 95/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1239 - accuracy: 0.6280 - val_loss: 1.1000 - val_accuracy: 0.6402\n",
      "Epoch 96/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1235 - accuracy: 0.6278 - val_loss: 1.1086 - val_accuracy: 0.6354\n",
      "Epoch 97/100\n",
      "938/938 [==============================] - 61s 66ms/step - loss: 1.1225 - accuracy: 0.6278 - val_loss: 1.1085 - val_accuracy: 0.6337\n",
      "Epoch 98/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1250 - accuracy: 0.6265 - val_loss: 1.1107 - val_accuracy: 0.6322\n",
      "Epoch 99/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1196 - accuracy: 0.6292 - val_loss: 1.0988 - val_accuracy: 0.6387\n",
      "Epoch 100/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1183 - accuracy: 0.6297 - val_loss: 1.0984 - val_accuracy: 0.6388\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BatchAccuracyLogger(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.batch_accuracies = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.batch_accuracies.append(logs.get('accuracy'))\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype(np.float32) / 255.0\n",
    "x_test = x_test.astype(np.float32) / 255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "xavier_initializer = tf.keras.initializers.GlorotNormal()\n",
    "identity_initializer = tf.keras.initializers.Identity()\n",
    "\n",
    "class Burgers(Model):\n",
    "    def __init__(self, num):\n",
    "        super(Burgers, self).__init__()\n",
    "        self.flatten = Flatten()\n",
    "        self.h1 = Dense(16, activation='tanh', kernel_initializer=xavier_initializer)\n",
    "        \n",
    "        self.hidden_layers = []\n",
    "        for _ in range(num):\n",
    "            self.hidden_layers.append(Dense(16, activation='tanh', kernel_initializer=xavier_initializer))\n",
    "            self.hidden_layers.append(Dense(4, activation='tanh', kernel_initializer=xavier_initializer))\n",
    "        self.u = Dense(10, activation='softmax')  \n",
    "    def call(self, state):\n",
    "        x = self.h1(state)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.flatten(x)  # Flatten the output before the final layer\n",
    "        out = self.u(x)\n",
    "        return out\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "\n",
    "    numbers = [50]\n",
    "    for num in numbers:\n",
    "        exec(f'xavier_acc128_{num} = []')  \n",
    "        exec(f'xavier_loss128_{num} = []')  \n",
    "        for _ in range(1): \n",
    "            loss_list1 = []\n",
    "            val_acc_list = []  \n",
    "            val_loss_list = [] \n",
    "            \n",
    "            model = Burgers(num=num)\n",
    "            model.compile(optimizer=Adam(0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            \n",
    "            batch_accuracy_logger = BatchAccuracyLogger()\n",
    "            \n",
    "            history = model.fit(x_train, y_train, epochs=100, batch_size=64, validation_data=(x_test, y_test))\n",
    "  \n",
    "            val_acc_list = history.history['val_accuracy']\n",
    "            val_loss_list = history.history['val_loss']\n",
    "\n",
    "            exec(f'xavier_acc128_{num}.append(val_acc_list)')\n",
    "            exec(f'xavier_loss128_{num}.append(val_loss_list)')\n",
    "\n",
    "            loss_list1.append(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ace32cab-bb64-40e3-a2ef-5922b642f2c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "938/938 [==============================] - 64s 65ms/step - loss: 2.1934 - accuracy: 0.2459 - val_loss: 2.0845 - val_accuracy: 0.2918\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 1.9908 - accuracy: 0.3374 - val_loss: 1.8963 - val_accuracy: 0.3925\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 1.8115 - accuracy: 0.4278 - val_loss: 1.7234 - val_accuracy: 0.4560\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 1.6492 - accuracy: 0.4886 - val_loss: 1.5693 - val_accuracy: 0.5123\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 1.5069 - accuracy: 0.5311 - val_loss: 1.4362 - val_accuracy: 0.5495\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.3831 - accuracy: 0.5661 - val_loss: 1.3250 - val_accuracy: 0.5773\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.2715 - accuracy: 0.5981 - val_loss: 1.2174 - val_accuracy: 0.6073\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.1740 - accuracy: 0.6257 - val_loss: 1.1307 - val_accuracy: 0.6356\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 1.0961 - accuracy: 0.6488 - val_loss: 1.0573 - val_accuracy: 0.6571\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 1.0325 - accuracy: 0.6646 - val_loss: 1.0011 - val_accuracy: 0.6659\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.9798 - accuracy: 0.6793 - val_loss: 0.9534 - val_accuracy: 0.6806\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.9351 - accuracy: 0.6907 - val_loss: 0.9153 - val_accuracy: 0.6941\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.8960 - accuracy: 0.7032 - val_loss: 0.8762 - val_accuracy: 0.7034\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.8627 - accuracy: 0.7126 - val_loss: 0.8446 - val_accuracy: 0.7156\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.8334 - accuracy: 0.7229 - val_loss: 0.8196 - val_accuracy: 0.7230\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.8082 - accuracy: 0.7298 - val_loss: 0.7957 - val_accuracy: 0.7339\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.7853 - accuracy: 0.7371 - val_loss: 0.7733 - val_accuracy: 0.7405\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.7652 - accuracy: 0.7449 - val_loss: 0.7548 - val_accuracy: 0.7450\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.7471 - accuracy: 0.7515 - val_loss: 0.7427 - val_accuracy: 0.7544\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.7302 - accuracy: 0.7592 - val_loss: 0.7219 - val_accuracy: 0.7624\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.7150 - accuracy: 0.7643 - val_loss: 0.7087 - val_accuracy: 0.7627\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.7016 - accuracy: 0.7702 - val_loss: 0.6980 - val_accuracy: 0.7725\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.6888 - accuracy: 0.7744 - val_loss: 0.6817 - val_accuracy: 0.7763\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.6765 - accuracy: 0.7801 - val_loss: 0.6712 - val_accuracy: 0.7809\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.6656 - accuracy: 0.7854 - val_loss: 0.6603 - val_accuracy: 0.7873\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.6551 - accuracy: 0.7887 - val_loss: 0.6522 - val_accuracy: 0.7856\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.6454 - accuracy: 0.7935 - val_loss: 0.6440 - val_accuracy: 0.7890\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.6371 - accuracy: 0.7962 - val_loss: 0.6328 - val_accuracy: 0.7946\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.6272 - accuracy: 0.8005 - val_loss: 0.6226 - val_accuracy: 0.7993\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.6188 - accuracy: 0.8041 - val_loss: 0.6176 - val_accuracy: 0.8027\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.6107 - accuracy: 0.8067 - val_loss: 0.6151 - val_accuracy: 0.8076\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.6030 - accuracy: 0.8102 - val_loss: 0.6011 - val_accuracy: 0.8077\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.5957 - accuracy: 0.8128 - val_loss: 0.5937 - val_accuracy: 0.8147\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.5881 - accuracy: 0.8157 - val_loss: 0.5865 - val_accuracy: 0.8149\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.5814 - accuracy: 0.8182 - val_loss: 0.5840 - val_accuracy: 0.8148\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.5752 - accuracy: 0.8202 - val_loss: 0.5739 - val_accuracy: 0.8167\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.5690 - accuracy: 0.8237 - val_loss: 0.5668 - val_accuracy: 0.8207\n",
      "Epoch 38/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.5625 - accuracy: 0.8258 - val_loss: 0.5607 - val_accuracy: 0.8265\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 0.5566 - accuracy: 0.8281 - val_loss: 0.5565 - val_accuracy: 0.8258\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.5506 - accuracy: 0.8300 - val_loss: 0.5486 - val_accuracy: 0.8314\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.5447 - accuracy: 0.8323 - val_loss: 0.5562 - val_accuracy: 0.8292\n",
      "Epoch 42/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.5399 - accuracy: 0.8335 - val_loss: 0.5382 - val_accuracy: 0.8334\n",
      "Epoch 43/100\n",
      "938/938 [==============================] - 62s 67ms/step - loss: 0.5347 - accuracy: 0.8354 - val_loss: 0.5345 - val_accuracy: 0.8324\n",
      "Epoch 44/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.5298 - accuracy: 0.8372 - val_loss: 0.5277 - val_accuracy: 0.8390\n",
      "Epoch 45/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.5252 - accuracy: 0.8388 - val_loss: 0.5273 - val_accuracy: 0.8397\n",
      "Epoch 46/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.5202 - accuracy: 0.8407 - val_loss: 0.5244 - val_accuracy: 0.8422\n",
      "Epoch 47/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.5158 - accuracy: 0.8423 - val_loss: 0.5153 - val_accuracy: 0.8418\n",
      "Epoch 48/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.5114 - accuracy: 0.8433 - val_loss: 0.5130 - val_accuracy: 0.8470\n",
      "Epoch 49/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.5075 - accuracy: 0.8447 - val_loss: 0.5113 - val_accuracy: 0.8468\n",
      "Epoch 50/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.5032 - accuracy: 0.8455 - val_loss: 0.5027 - val_accuracy: 0.8479\n",
      "Epoch 51/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4987 - accuracy: 0.8476 - val_loss: 0.4996 - val_accuracy: 0.8487\n",
      "Epoch 52/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4950 - accuracy: 0.8488 - val_loss: 0.4939 - val_accuracy: 0.8525\n",
      "Epoch 53/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4909 - accuracy: 0.8505 - val_loss: 0.4958 - val_accuracy: 0.8496\n",
      "Epoch 54/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4871 - accuracy: 0.8510 - val_loss: 0.4872 - val_accuracy: 0.8516\n",
      "Epoch 55/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4840 - accuracy: 0.8520 - val_loss: 0.4845 - val_accuracy: 0.8527\n",
      "Epoch 56/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 0.4799 - accuracy: 0.8536 - val_loss: 0.4780 - val_accuracy: 0.8558\n",
      "Epoch 57/100\n",
      "938/938 [==============================] - 60s 65ms/step - loss: 0.4764 - accuracy: 0.8547 - val_loss: 0.4763 - val_accuracy: 0.8543\n",
      "Epoch 58/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4734 - accuracy: 0.8561 - val_loss: 0.4713 - val_accuracy: 0.8579\n",
      "Epoch 59/100\n",
      "938/938 [==============================] - 61s 66ms/step - loss: 0.4692 - accuracy: 0.8576 - val_loss: 0.4762 - val_accuracy: 0.8591\n",
      "Epoch 60/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4662 - accuracy: 0.8589 - val_loss: 0.4734 - val_accuracy: 0.8599\n",
      "Epoch 61/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4631 - accuracy: 0.8597 - val_loss: 0.4628 - val_accuracy: 0.8598\n",
      "Epoch 62/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4601 - accuracy: 0.8601 - val_loss: 0.4590 - val_accuracy: 0.8627\n",
      "Epoch 63/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4574 - accuracy: 0.8615 - val_loss: 0.4632 - val_accuracy: 0.8633\n",
      "Epoch 64/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4543 - accuracy: 0.8626 - val_loss: 0.4573 - val_accuracy: 0.8648\n",
      "Epoch 65/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4512 - accuracy: 0.8633 - val_loss: 0.4507 - val_accuracy: 0.8660\n",
      "Epoch 66/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4486 - accuracy: 0.8649 - val_loss: 0.4488 - val_accuracy: 0.8680\n",
      "Epoch 67/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4458 - accuracy: 0.8660 - val_loss: 0.4485 - val_accuracy: 0.8681\n",
      "Epoch 68/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4431 - accuracy: 0.8665 - val_loss: 0.4437 - val_accuracy: 0.8695\n",
      "Epoch 69/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4408 - accuracy: 0.8680 - val_loss: 0.4392 - val_accuracy: 0.8702\n",
      "Epoch 70/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 0.4374 - accuracy: 0.8687 - val_loss: 0.4341 - val_accuracy: 0.8724\n",
      "Epoch 71/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4350 - accuracy: 0.8695 - val_loss: 0.4340 - val_accuracy: 0.8725\n",
      "Epoch 72/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.4323 - accuracy: 0.8699 - val_loss: 0.4305 - val_accuracy: 0.8732\n",
      "Epoch 73/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.4299 - accuracy: 0.8708 - val_loss: 0.4331 - val_accuracy: 0.8722\n",
      "Epoch 74/100\n",
      "938/938 [==============================] - 61s 66ms/step - loss: 0.4271 - accuracy: 0.8716 - val_loss: 0.4269 - val_accuracy: 0.8752\n",
      "Epoch 75/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4247 - accuracy: 0.8725 - val_loss: 0.4219 - val_accuracy: 0.8758\n",
      "Epoch 76/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4225 - accuracy: 0.8731 - val_loss: 0.4204 - val_accuracy: 0.8755\n",
      "Epoch 77/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4202 - accuracy: 0.8739 - val_loss: 0.4162 - val_accuracy: 0.8785\n",
      "Epoch 78/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4178 - accuracy: 0.8748 - val_loss: 0.4151 - val_accuracy: 0.8773\n",
      "Epoch 79/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4155 - accuracy: 0.8750 - val_loss: 0.4127 - val_accuracy: 0.8787\n",
      "Epoch 80/100\n",
      "938/938 [==============================] - 61s 66ms/step - loss: 0.4133 - accuracy: 0.8762 - val_loss: 0.4103 - val_accuracy: 0.8801\n",
      "Epoch 81/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 0.4109 - accuracy: 0.8769 - val_loss: 0.4096 - val_accuracy: 0.8802\n",
      "Epoch 82/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4086 - accuracy: 0.8777 - val_loss: 0.4132 - val_accuracy: 0.8793\n",
      "Epoch 83/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4067 - accuracy: 0.8781 - val_loss: 0.4050 - val_accuracy: 0.8800\n",
      "Epoch 84/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.4044 - accuracy: 0.8788 - val_loss: 0.4103 - val_accuracy: 0.8796\n",
      "Epoch 85/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 0.4020 - accuracy: 0.8794 - val_loss: 0.4048 - val_accuracy: 0.8808\n",
      "Epoch 86/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.3999 - accuracy: 0.8802 - val_loss: 0.3992 - val_accuracy: 0.8829\n",
      "Epoch 87/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 0.3979 - accuracy: 0.8808 - val_loss: 0.3953 - val_accuracy: 0.8855\n",
      "Epoch 88/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.3961 - accuracy: 0.8820 - val_loss: 0.3932 - val_accuracy: 0.8845\n",
      "Epoch 89/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.3940 - accuracy: 0.8815 - val_loss: 0.3907 - val_accuracy: 0.8855\n",
      "Epoch 90/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 0.3917 - accuracy: 0.8822 - val_loss: 0.3915 - val_accuracy: 0.8860\n",
      "Epoch 91/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 0.3903 - accuracy: 0.8827 - val_loss: 0.3853 - val_accuracy: 0.8881\n",
      "Epoch 92/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 0.3881 - accuracy: 0.8848 - val_loss: 0.3849 - val_accuracy: 0.8868\n",
      "Epoch 93/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.3863 - accuracy: 0.8844 - val_loss: 0.3814 - val_accuracy: 0.8881\n",
      "Epoch 94/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.3849 - accuracy: 0.8848 - val_loss: 0.3823 - val_accuracy: 0.8869\n",
      "Epoch 95/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 0.3825 - accuracy: 0.8853 - val_loss: 0.3791 - val_accuracy: 0.8892\n",
      "Epoch 96/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.3805 - accuracy: 0.8865 - val_loss: 0.3795 - val_accuracy: 0.8884\n",
      "Epoch 97/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 0.3793 - accuracy: 0.8865 - val_loss: 0.3740 - val_accuracy: 0.8905\n",
      "Epoch 98/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 0.3771 - accuracy: 0.8874 - val_loss: 0.3741 - val_accuracy: 0.8913\n",
      "Epoch 99/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.3756 - accuracy: 0.8874 - val_loss: 0.3718 - val_accuracy: 0.8926\n",
      "Epoch 100/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 0.3739 - accuracy: 0.8884 - val_loss: 0.3717 - val_accuracy: 0.8909\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "class Proposed(tf.keras.initializers.Initializer):\n",
    "    def __call__(self, shape, dtype=None):\n",
    "        m, n = shape\n",
    "        \n",
    "        if m >= n:\n",
    "            identity_matrix = np.eye(m, n, dtype=np.float32)\n",
    "        else:\n",
    "            identity_matrix = np.zeros((n, m), dtype=np.float32)\n",
    "            for i in range(n):\n",
    "                identity_matrix[i, i % m] = 1\n",
    "            identity_matrix = identity_matrix.transpose()\n",
    "        \n",
    "        std = 0.085 * (1 / np.sqrt(n))\n",
    "        noise = np.random.normal(0, std, size=(shape[0], shape[1]))\n",
    "        identity_matrix += noise\n",
    "        return identity_matrix\n",
    "\n",
    "\n",
    "class BatchAccuracyLogger(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.batch_accuracies = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.batch_accuracies.append(logs.get('accuracy'))\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(np.float32) / 255.0\n",
    "x_test = x_test.astype(np.float32) / 255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "xavier_initializer = tf.keras.initializers.GlorotNormal()\n",
    "identity_initializer = tf.keras.initializers.Identity()\n",
    "\n",
    "class Burgers(Model):\n",
    "    def __init__(self, num):\n",
    "        super(Burgers, self).__init__()\n",
    "        self.flatten = Flatten()\n",
    "        self.h1 = Dense(16, activation='tanh', kernel_initializer=Proposed())\n",
    "        self.hidden_layers = []\n",
    "        for _ in range(num):\n",
    "            self.hidden_layers.append(Dense(16, activation='tanh', kernel_initializer=Proposed()))\n",
    "            self.hidden_layers.append(Dense(4, activation='tanh', kernel_initializer=Proposed()))\n",
    "        self.u = Dense(10, activation='softmax')  \n",
    "    def call(self, state):\n",
    "        x = self.h1(state)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.flatten(x)  \n",
    "        out = self.u(x)\n",
    "        return out\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "\n",
    "    numbers = [50]\n",
    "    for num in numbers:\n",
    "        exec(f'proposed_acc128_{num} = []')  \n",
    "        exec(f'proposed_loss128_{num} = []')  \n",
    "        for _ in range(1):  \n",
    "            loss_list1 = []\n",
    "            val_acc_list = [] \n",
    "            val_loss_list = [] \n",
    "            \n",
    "            model = Burgers(num=num)\n",
    "            model.compile(optimizer=Adam(0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            batch_accuracy_logger = BatchAccuracyLogger()  \n",
    "            history = model.fit(x_train, y_train, epochs=100, batch_size=64, validation_data=(x_test, y_test))\n",
    "            val_acc_list = history.history['val_accuracy']\n",
    "            val_loss_list = history.history['val_loss']\n",
    "\n",
    "            exec(f'proposed_acc128_{num}.append(val_acc_list)')\n",
    "            exec(f'proposed_loss128_{num}.append(val_loss_list)')\n",
    "            \n",
    "            # Plot loss history\n",
    "            loss_list1.append(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed3a09f9-adf4-42bb-82b1-0f19771f4c91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "938/938 [==============================] - 211s 215ms/step - loss: 2.7406 - accuracy: 0.1019 - val_loss: 2.3727 - val_accuracy: 0.0936\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 200s 213ms/step - loss: 2.6656 - accuracy: 0.1034 - val_loss: 2.3259 - val_accuracy: 0.1139\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 199s 213ms/step - loss: 2.6109 - accuracy: 0.1038 - val_loss: 2.4020 - val_accuracy: 0.1099\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 200s 213ms/step - loss: 2.5733 - accuracy: 0.1054 - val_loss: 2.3126 - val_accuracy: 0.1135\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 199s 212ms/step - loss: 2.5463 - accuracy: 0.1073 - val_loss: 2.3470 - val_accuracy: 0.1187\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 199s 212ms/step - loss: 2.5201 - accuracy: 0.1086 - val_loss: 2.3317 - val_accuracy: 0.1283\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 199s 212ms/step - loss: 2.4867 - accuracy: 0.1123 - val_loss: 2.3814 - val_accuracy: 0.1356\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 198s 212ms/step - loss: 2.4642 - accuracy: 0.1126 - val_loss: 2.3221 - val_accuracy: 0.0892\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 200s 213ms/step - loss: 2.4376 - accuracy: 0.1169 - val_loss: 2.4855 - val_accuracy: 0.1020\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 199s 212ms/step - loss: 2.4195 - accuracy: 0.1169 - val_loss: 2.3153 - val_accuracy: 0.1263\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.4072 - accuracy: 0.1184 - val_loss: 2.3194 - val_accuracy: 0.1202\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.3908 - accuracy: 0.1209 - val_loss: 2.3065 - val_accuracy: 0.1352\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.3790 - accuracy: 0.1258 - val_loss: 2.3124 - val_accuracy: 0.1205\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.3636 - accuracy: 0.1295 - val_loss: 2.3077 - val_accuracy: 0.1453\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 196s 209ms/step - loss: 2.3555 - accuracy: 0.1294 - val_loss: 2.3397 - val_accuracy: 0.1290\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.3471 - accuracy: 0.1326 - val_loss: 2.3153 - val_accuracy: 0.1177\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.3386 - accuracy: 0.1364 - val_loss: 2.3100 - val_accuracy: 0.1282\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.3284 - accuracy: 0.1357 - val_loss: 2.3315 - val_accuracy: 0.0607\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 197s 211ms/step - loss: 2.3223 - accuracy: 0.1417 - val_loss: 2.3089 - val_accuracy: 0.1138\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.3158 - accuracy: 0.1438 - val_loss: 2.3866 - val_accuracy: 0.0701\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.3063 - accuracy: 0.1469 - val_loss: 2.3002 - val_accuracy: 0.1350\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.3004 - accuracy: 0.1486 - val_loss: 2.3170 - val_accuracy: 0.1101\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.2965 - accuracy: 0.1511 - val_loss: 2.2682 - val_accuracy: 0.1608\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 199s 212ms/step - loss: 2.2862 - accuracy: 0.1578 - val_loss: 2.2985 - val_accuracy: 0.1500\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.2809 - accuracy: 0.1558 - val_loss: 2.3094 - val_accuracy: 0.1233\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.2727 - accuracy: 0.1606 - val_loss: 2.3164 - val_accuracy: 0.1172\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 199s 212ms/step - loss: 2.2648 - accuracy: 0.1664 - val_loss: 2.3068 - val_accuracy: 0.1195\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 199s 212ms/step - loss: 2.2629 - accuracy: 0.1648 - val_loss: 2.3051 - val_accuracy: 0.1205\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.2526 - accuracy: 0.1684 - val_loss: 2.2815 - val_accuracy: 0.1368\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.2447 - accuracy: 0.1745 - val_loss: 2.4241 - val_accuracy: 0.1073\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.2403 - accuracy: 0.1771 - val_loss: 2.2805 - val_accuracy: 0.1315\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 196s 209ms/step - loss: 2.2303 - accuracy: 0.1802 - val_loss: 2.2947 - val_accuracy: 0.1352\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 196s 209ms/step - loss: 2.2303 - accuracy: 0.1836 - val_loss: 2.2532 - val_accuracy: 0.1721\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.2257 - accuracy: 0.1842 - val_loss: 2.3207 - val_accuracy: 0.1187\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 197s 211ms/step - loss: 2.2205 - accuracy: 0.1856 - val_loss: 2.2788 - val_accuracy: 0.1369\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.2164 - accuracy: 0.1870 - val_loss: 2.3101 - val_accuracy: 0.1236\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 199s 212ms/step - loss: 2.2089 - accuracy: 0.1925 - val_loss: 2.2317 - val_accuracy: 0.1689\n",
      "Epoch 38/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.2031 - accuracy: 0.1928 - val_loss: 2.2828 - val_accuracy: 0.1538\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.2007 - accuracy: 0.1948 - val_loss: 5.1910 - val_accuracy: 0.0973\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.1910 - accuracy: 0.1997 - val_loss: 2.2974 - val_accuracy: 0.1370\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.1840 - accuracy: 0.2047 - val_loss: 2.2936 - val_accuracy: 0.1301\n",
      "Epoch 42/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.1852 - accuracy: 0.2026 - val_loss: 2.9052 - val_accuracy: 0.0414\n",
      "Epoch 43/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.1720 - accuracy: 0.2088 - val_loss: 2.3104 - val_accuracy: 0.1271\n",
      "Epoch 44/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.1642 - accuracy: 0.2133 - val_loss: 3.5825 - val_accuracy: 0.0322\n",
      "Epoch 45/100\n",
      "938/938 [==============================] - 197s 211ms/step - loss: 2.1605 - accuracy: 0.2162 - val_loss: 2.1174 - val_accuracy: 0.2403\n",
      "Epoch 46/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.1549 - accuracy: 0.2181 - val_loss: 3.0555 - val_accuracy: 0.0988\n",
      "Epoch 47/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.1488 - accuracy: 0.2197 - val_loss: 3.1885 - val_accuracy: 0.0839\n",
      "Epoch 48/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.1418 - accuracy: 0.2226 - val_loss: 2.3852 - val_accuracy: 0.0723\n",
      "Epoch 49/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.1368 - accuracy: 0.2277 - val_loss: 2.3053 - val_accuracy: 0.1301\n",
      "Epoch 50/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.1330 - accuracy: 0.2285 - val_loss: 2.2648 - val_accuracy: 0.1434\n",
      "Epoch 51/100\n",
      "938/938 [==============================] - 196s 209ms/step - loss: 2.1367 - accuracy: 0.2231 - val_loss: 2.5371 - val_accuracy: 0.0251\n",
      "Epoch 52/100\n",
      "938/938 [==============================] - 198s 212ms/step - loss: 2.1400 - accuracy: 0.2221 - val_loss: 3.9097 - val_accuracy: 0.0827\n",
      "Epoch 53/100\n",
      "938/938 [==============================] - 199s 212ms/step - loss: 2.1210 - accuracy: 0.2335 - val_loss: 4.0883 - val_accuracy: 0.0539\n",
      "Epoch 54/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.1146 - accuracy: 0.2329 - val_loss: 2.4193 - val_accuracy: 0.0944\n",
      "Epoch 55/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.1166 - accuracy: 0.2307 - val_loss: 2.2740 - val_accuracy: 0.1464\n",
      "Epoch 56/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.1128 - accuracy: 0.2333 - val_loss: 2.6544 - val_accuracy: 0.0118\n",
      "Epoch 57/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.1167 - accuracy: 0.2312 - val_loss: 2.3107 - val_accuracy: 0.1581\n",
      "Epoch 58/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.1130 - accuracy: 0.2314 - val_loss: 2.2456 - val_accuracy: 0.1564\n",
      "Epoch 59/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.1153 - accuracy: 0.2272 - val_loss: 2.3513 - val_accuracy: 0.1239\n",
      "Epoch 60/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.0933 - accuracy: 0.2394 - val_loss: 2.1924 - val_accuracy: 0.1818\n",
      "Epoch 61/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.0985 - accuracy: 0.2388 - val_loss: 2.6322 - val_accuracy: 0.0323\n",
      "Epoch 62/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.1087 - accuracy: 0.2337 - val_loss: 2.4082 - val_accuracy: 0.1055\n",
      "Epoch 63/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.0924 - accuracy: 0.2430 - val_loss: 3.9682 - val_accuracy: 0.0336\n",
      "Epoch 64/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.0918 - accuracy: 0.2424 - val_loss: 2.5963 - val_accuracy: 0.0564\n",
      "Epoch 65/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.0908 - accuracy: 0.2408 - val_loss: 2.2687 - val_accuracy: 0.1478\n",
      "Epoch 66/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.0802 - accuracy: 0.2415 - val_loss: 2.3948 - val_accuracy: 0.1023\n",
      "Epoch 67/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.0991 - accuracy: 0.2372 - val_loss: 4.0212 - val_accuracy: 0.0979\n",
      "Epoch 68/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.0865 - accuracy: 0.2418 - val_loss: 2.1906 - val_accuracy: 0.1933\n",
      "Epoch 69/100\n",
      "938/938 [==============================] - 195s 208ms/step - loss: 2.0858 - accuracy: 0.2427 - val_loss: 2.2458 - val_accuracy: 0.1572\n",
      "Epoch 70/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.0789 - accuracy: 0.2453 - val_loss: 2.2422 - val_accuracy: 0.1572\n",
      "Epoch 71/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.0815 - accuracy: 0.2436 - val_loss: 2.3523 - val_accuracy: 0.1141\n",
      "Epoch 72/100\n",
      "938/938 [==============================] - 196s 209ms/step - loss: 2.0809 - accuracy: 0.2430 - val_loss: 2.1074 - val_accuracy: 0.2134\n",
      "Epoch 73/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.0735 - accuracy: 0.2437 - val_loss: 2.6365 - val_accuracy: 0.0455\n",
      "Epoch 74/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.0794 - accuracy: 0.2443 - val_loss: 2.1199 - val_accuracy: 0.1853\n",
      "Epoch 75/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.0686 - accuracy: 0.2501 - val_loss: 4.1392 - val_accuracy: 0.0195\n",
      "Epoch 76/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.0714 - accuracy: 0.2494 - val_loss: 2.3096 - val_accuracy: 0.1636\n",
      "Epoch 77/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.0625 - accuracy: 0.2519 - val_loss: 2.3795 - val_accuracy: 0.1036\n",
      "Epoch 78/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.0642 - accuracy: 0.2511 - val_loss: 2.3063 - val_accuracy: 0.0960\n",
      "Epoch 79/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.0638 - accuracy: 0.2512 - val_loss: 4.4003 - val_accuracy: 0.0686\n",
      "Epoch 80/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.0625 - accuracy: 0.2483 - val_loss: 3.7412 - val_accuracy: 0.0976\n",
      "Epoch 81/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.0421 - accuracy: 0.2601 - val_loss: 3.6371 - val_accuracy: 0.0721\n",
      "Epoch 82/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.0386 - accuracy: 0.2594 - val_loss: 3.9702 - val_accuracy: 0.0807\n",
      "Epoch 83/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.0341 - accuracy: 0.2639 - val_loss: 2.6128 - val_accuracy: 0.0968\n",
      "Epoch 84/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.0350 - accuracy: 0.2637 - val_loss: 2.1643 - val_accuracy: 0.1993\n",
      "Epoch 85/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.0407 - accuracy: 0.2623 - val_loss: 2.2118 - val_accuracy: 0.1451\n",
      "Epoch 86/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.0242 - accuracy: 0.2675 - val_loss: 2.3044 - val_accuracy: 0.1339\n",
      "Epoch 87/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.0195 - accuracy: 0.2684 - val_loss: 3.2057 - val_accuracy: 0.0713\n",
      "Epoch 88/100\n",
      "938/938 [==============================] - 197s 210ms/step - loss: 2.0343 - accuracy: 0.2604 - val_loss: 2.8506 - val_accuracy: 0.0999\n",
      "Epoch 89/100\n",
      "938/938 [==============================] - 198s 211ms/step - loss: 2.0383 - accuracy: 0.2598 - val_loss: 2.4350 - val_accuracy: 0.0880\n",
      "Epoch 90/100\n",
      "938/938 [==============================] - 199s 212ms/step - loss: 2.0511 - accuracy: 0.2569 - val_loss: 2.5370 - val_accuracy: 0.0990\n",
      "Epoch 91/100\n",
      "938/938 [==============================] - 199s 212ms/step - loss: 2.0235 - accuracy: 0.2672 - val_loss: 2.3358 - val_accuracy: 0.1232\n",
      "Epoch 92/100\n",
      "938/938 [==============================] - 200s 213ms/step - loss: 2.0269 - accuracy: 0.2668 - val_loss: 2.5913 - val_accuracy: 0.0780\n",
      "Epoch 93/100\n",
      "938/938 [==============================] - 200s 213ms/step - loss: 2.0273 - accuracy: 0.2664 - val_loss: 2.1504 - val_accuracy: 0.2053\n",
      "Epoch 94/100\n",
      "938/938 [==============================] - 200s 213ms/step - loss: 2.0243 - accuracy: 0.2657 - val_loss: 2.1873 - val_accuracy: 0.1825\n",
      "Epoch 95/100\n",
      "938/938 [==============================] - 199s 212ms/step - loss: 2.0120 - accuracy: 0.2694 - val_loss: 3.0643 - val_accuracy: 0.0923\n",
      "Epoch 96/100\n",
      "938/938 [==============================] - 199s 212ms/step - loss: 2.0115 - accuracy: 0.2688 - val_loss: 2.3224 - val_accuracy: 0.2022\n",
      "Epoch 97/100\n",
      "938/938 [==============================] - 200s 213ms/step - loss: 2.0040 - accuracy: 0.2714 - val_loss: 2.8533 - val_accuracy: 0.0694\n",
      "Epoch 98/100\n",
      "938/938 [==============================] - 200s 213ms/step - loss: 2.0041 - accuracy: 0.2718 - val_loss: 2.3146 - val_accuracy: 0.1508\n",
      "Epoch 99/100\n",
      "938/938 [==============================] - 199s 212ms/step - loss: 2.0002 - accuracy: 0.2734 - val_loss: 2.8459 - val_accuracy: 0.0560\n",
      "Epoch 100/100\n",
      "938/938 [==============================] - 199s 213ms/step - loss: 2.0058 - accuracy: 0.2722 - val_loss: 2.5967 - val_accuracy: 0.1088\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "class Proposed(tf.keras.initializers.Initializer):\n",
    "    def __call__(self, shape, dtype=None):\n",
    "        m, n = shape\n",
    "        \n",
    "        if m >= n:\n",
    "            identity_matrix = np.eye(m, n, dtype=np.float32)\n",
    "        else:\n",
    "            identity_matrix = np.zeros((n, m), dtype=np.float32)\n",
    "            for i in range(n):\n",
    "                identity_matrix[i, i % m] = 1\n",
    "            identity_matrix = identity_matrix.transpose()\n",
    "        \n",
    "        std = 0.085 * (1 / np.sqrt(n))\n",
    "        noise = np.random.normal(0, std, size=(shape[0], shape[1]))\n",
    "        identity_matrix += noise\n",
    "        return identity_matrix\n",
    "\n",
    "\n",
    "class BatchAccuracyLogger(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.batch_accuracies = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.batch_accuracies.append(logs.get('accuracy'))\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype(np.float32) / 255.0\n",
    "x_test = x_test.astype(np.float32) / 255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "xavier_initializer = tf.keras.initializers.GlorotNormal()\n",
    "He_initializer = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "class Burgers(Model):\n",
    "    def __init__(self, num):\n",
    "        super(Burgers, self).__init__()\n",
    "        self.flatten = Flatten()\n",
    "        self.h1 = Dense(16, use_bias=False, kernel_initializer=He_initializer)\n",
    "        self.h1_bn = BatchNormalization()\n",
    "        self.hidden_layers = []\n",
    "        for _ in range(num):\n",
    "            self.hidden_layers.append((Dense(16, kernel_initializer=He_initializer), BatchNormalization()))\n",
    "            self.hidden_layers.append((Dense(4, kernel_initializer=He_initializer), BatchNormalization()))\n",
    "        self.u = Dense(10, activation='softmax')  \n",
    "        \n",
    "    def call(self, state, training=False):\n",
    "        x = self.h1(state)\n",
    "        x = self.h1_bn(x, training=training)\n",
    "        x = tf.nn.relu(x) \n",
    "        \n",
    "        for dense_layer, batch_norm in self.hidden_layers:\n",
    "            x = dense_layer(x)\n",
    "            x = batch_norm(x, training=training)\n",
    "            x = tf.nn.relu(x)  \n",
    "            \n",
    "        x = self.flatten(x)  \n",
    "        out = self.u(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "\n",
    "    numbers = [50]\n",
    "    for num in numbers:\n",
    "        exec(f'hebatch_acc128_{num} = []')  \n",
    "        exec(f'hebatch_loss128_{num} = []')  \n",
    "        for _ in range(1): \n",
    "            loss_list1 = []\n",
    "            val_acc_list = []  \n",
    "            val_loss_list = []  \n",
    "            \n",
    "            model = Burgers(num=num)\n",
    "            model.compile(optimizer=Adam(0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            \n",
    "            batch_accuracy_logger = BatchAccuracyLogger()\n",
    "            \n",
    "            history = model.fit(x_train, y_train, epochs=100, batch_size=64, validation_data=(x_test, y_test))\n",
    "\n",
    "            val_acc_list = history.history['val_accuracy']\n",
    "            val_loss_list = history.history['val_loss']\n",
    "\n",
    "            exec(f'hebatch_acc128_{num}.append(val_acc_list)')\n",
    "            exec(f'hebatch_loss128_{num}.append(val_loss_list)')\n",
    "            \n",
    "            loss_list1.append(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72256ff6-492e-4c76-8c2c-bb122c4d1809",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "938/938 [==============================] - 65s 66ms/step - loss: 2.3026 - accuracy: 0.1111 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3025 - accuracy: 0.1124 - val_loss: 2.3024 - val_accuracy: 0.1135\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3024 - accuracy: 0.1124 - val_loss: 2.3024 - val_accuracy: 0.1135\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3024 - accuracy: 0.1124 - val_loss: 2.3023 - val_accuracy: 0.1135\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3023 - accuracy: 0.1124 - val_loss: 2.3023 - val_accuracy: 0.1135\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3023 - accuracy: 0.1124 - val_loss: 2.3022 - val_accuracy: 0.1135\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3022 - accuracy: 0.1124 - val_loss: 2.3022 - val_accuracy: 0.1135\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3022 - accuracy: 0.1124 - val_loss: 2.3021 - val_accuracy: 0.1135\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3021 - accuracy: 0.1124 - val_loss: 2.3021 - val_accuracy: 0.1135\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 61s 66ms/step - loss: 2.3021 - accuracy: 0.1124 - val_loss: 2.3020 - val_accuracy: 0.1135\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3020 - accuracy: 0.1124 - val_loss: 2.3020 - val_accuracy: 0.1135\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3020 - accuracy: 0.1124 - val_loss: 2.3019 - val_accuracy: 0.1135\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3019 - accuracy: 0.1124 - val_loss: 2.3019 - val_accuracy: 0.1135\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3019 - accuracy: 0.1124 - val_loss: 2.3018 - val_accuracy: 0.1135\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.3019 - accuracy: 0.1124 - val_loss: 2.3018 - val_accuracy: 0.1135\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3018 - accuracy: 0.1124 - val_loss: 2.3018 - val_accuracy: 0.1135\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.3018 - accuracy: 0.1124 - val_loss: 2.3017 - val_accuracy: 0.1135\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3018 - accuracy: 0.1124 - val_loss: 2.3017 - val_accuracy: 0.1135\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3017 - accuracy: 0.1124 - val_loss: 2.3017 - val_accuracy: 0.1135\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3017 - accuracy: 0.1124 - val_loss: 2.3016 - val_accuracy: 0.1135\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3017 - accuracy: 0.1124 - val_loss: 2.3016 - val_accuracy: 0.1135\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3017 - accuracy: 0.1124 - val_loss: 2.3016 - val_accuracy: 0.1135\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3016 - accuracy: 0.1124 - val_loss: 2.3016 - val_accuracy: 0.1135\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3016 - accuracy: 0.1124 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3016 - accuracy: 0.1124 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3016 - accuracy: 0.1124 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 38/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 42/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 43/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 44/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 45/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 46/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 47/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 48/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 49/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 50/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 51/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 52/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 53/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 54/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 55/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 56/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 57/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 58/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 59/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 60/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 61/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 62/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 63/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 64/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 65/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 66/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 67/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 68/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 69/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 70/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 71/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 72/100\n",
      "938/938 [==============================] - 61s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 73/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 74/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 75/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 76/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 77/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 78/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 79/100\n",
      "938/938 [==============================] - 61s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 80/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 81/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 82/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 83/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 84/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 85/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 86/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 87/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 88/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 89/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 90/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 91/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 92/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 93/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 94/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 95/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 96/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 97/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 98/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 99/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 100/100\n",
      "938/938 [==============================] - 61s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BatchAccuracyLogger(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.batch_accuracies = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.batch_accuracies.append(logs.get('accuracy'))\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype(np.float32) / 255.0\n",
    "x_test = x_test.astype(np.float32) / 255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "xavier_initializer = tf.keras.initializers.GlorotNormal()\n",
    "orthogonal_initializer = tf.keras.initializers.Orthogonal()\n",
    "\n",
    "class Burgers(Model):\n",
    "    def __init__(self, num):\n",
    "        super(Burgers, self).__init__()\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "        self.h1 = Dense(16, activation='relu', kernel_initializer=orthogonal_initializer)\n",
    "        \n",
    "        self.hidden_layers = []\n",
    "        for _ in range(num):\n",
    "            self.hidden_layers.append(Dense(16, activation='relu', kernel_initializer=orthogonal_initializer))\n",
    "            self.hidden_layers.append(Dense(4, activation='relu', kernel_initializer=orthogonal_initializer))\n",
    "        self.u = Dense(10, activation='softmax')  \n",
    "    def call(self, state):\n",
    "        x = self.h1(state)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.flatten(x)  \n",
    "        out = self.u(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "\n",
    "    numbers = [50]\n",
    "    for num in numbers:\n",
    "        exec(f'orthogonal_acc128_{num} = []')  \n",
    "        exec(f'orthogonal_loss128_{num} = []')  \n",
    "        for _ in range(1):  \n",
    "            loss_list1 = []\n",
    "            val_acc_list = [] \n",
    "            val_loss_list = []  \n",
    "            \n",
    "            model = Burgers(num=num)\n",
    "            model.compile(optimizer=Adam(0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            \n",
    "            batch_accuracy_logger = BatchAccuracyLogger()\n",
    "            \n",
    "            history = model.fit(x_train, y_train, epochs=100, batch_size=64, validation_data=(x_test, y_test))\n",
    "\n",
    "            val_acc_list = history.history['val_accuracy']\n",
    "            val_loss_list = history.history['val_loss']\n",
    "\n",
    "            exec(f'orthogonal_acc128_{num}.append(val_acc_list)')\n",
    "            exec(f'orthogonal_loss128_{num}.append(val_loss_list)')\n",
    "            \n",
    "            loss_list1.append(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f3dddc3-0b7c-430c-bf40-7fbbca5e0a02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "938/938 [==============================] - 65s 66ms/step - loss: 2.3026 - accuracy: 0.1123 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 61s 66ms/step - loss: 2.3025 - accuracy: 0.1124 - val_loss: 2.3024 - val_accuracy: 0.1135\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3024 - accuracy: 0.1124 - val_loss: 2.3024 - val_accuracy: 0.1135\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3024 - accuracy: 0.1124 - val_loss: 2.3023 - val_accuracy: 0.1135\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 61s 66ms/step - loss: 2.3023 - accuracy: 0.1124 - val_loss: 2.3023 - val_accuracy: 0.1135\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3023 - accuracy: 0.1124 - val_loss: 2.3022 - val_accuracy: 0.1135\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3022 - accuracy: 0.1124 - val_loss: 2.3022 - val_accuracy: 0.1135\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3022 - accuracy: 0.1124 - val_loss: 2.3021 - val_accuracy: 0.1135\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3021 - accuracy: 0.1124 - val_loss: 2.3021 - val_accuracy: 0.1135\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 61s 66ms/step - loss: 2.3021 - accuracy: 0.1124 - val_loss: 2.3020 - val_accuracy: 0.1135\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3020 - accuracy: 0.1124 - val_loss: 2.3020 - val_accuracy: 0.1135\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3020 - accuracy: 0.1124 - val_loss: 2.3019 - val_accuracy: 0.1135\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3019 - accuracy: 0.1124 - val_loss: 2.3019 - val_accuracy: 0.1135\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3019 - accuracy: 0.1124 - val_loss: 2.3018 - val_accuracy: 0.1135\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3019 - accuracy: 0.1124 - val_loss: 2.3018 - val_accuracy: 0.1135\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3018 - accuracy: 0.1124 - val_loss: 2.3018 - val_accuracy: 0.1135\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3018 - accuracy: 0.1124 - val_loss: 2.3017 - val_accuracy: 0.1135\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3018 - accuracy: 0.1124 - val_loss: 2.3017 - val_accuracy: 0.1135\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3017 - accuracy: 0.1124 - val_loss: 2.3017 - val_accuracy: 0.1135\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3017 - accuracy: 0.1124 - val_loss: 2.3016 - val_accuracy: 0.1135\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3017 - accuracy: 0.1124 - val_loss: 2.3016 - val_accuracy: 0.1135\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3017 - accuracy: 0.1124 - val_loss: 2.3016 - val_accuracy: 0.1135\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3016 - accuracy: 0.1124 - val_loss: 2.3016 - val_accuracy: 0.1135\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3016 - accuracy: 0.1124 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3016 - accuracy: 0.1124 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3016 - accuracy: 0.1124 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3016 - accuracy: 0.1124 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 61s 66ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 59s 63ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 38/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 42/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 43/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 44/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 45/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 46/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 47/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 48/100\n",
      "938/938 [==============================] - 61s 66ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 49/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 50/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 51/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 52/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 53/100\n",
      "938/938 [==============================] - 61s 66ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 54/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 55/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 56/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 57/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 58/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 59/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 60/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 61/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 62/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 63/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 64/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 65/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 66/100\n",
      "938/938 [==============================] - 61s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 67/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 68/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 69/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 70/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 71/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 72/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 73/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 74/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 75/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 76/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 77/100\n",
      "938/938 [==============================] - 63s 67ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 78/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 79/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 80/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 81/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 82/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 83/100\n",
      "938/938 [==============================] - 61s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 84/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 85/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 86/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 87/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 88/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 89/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 90/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 91/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 92/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 93/100\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 94/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 95/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 96/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 97/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 98/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 99/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 100/100\n",
      "938/938 [==============================] - 62s 66ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BatchAccuracyLogger(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.batch_accuracies = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.batch_accuracies.append(logs.get('accuracy'))\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype(np.float32) / 255.0\n",
    "x_test = x_test.astype(np.float32) / 255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "xavier_initializer = tf.keras.initializers.GlorotNormal()\n",
    "orthogonal_initializer = tf.keras.initializers.Orthogonal()\n",
    "\n",
    "class Burgers(Model):\n",
    "    def __init__(self, num):\n",
    "        super(Burgers, self).__init__()\n",
    "        self.flatten = Flatten()\n",
    "        self.h1 = Dense(16, activation='relu', kernel_initializer=He_initializer)\n",
    "        \n",
    "        self.hidden_layers = []\n",
    "        for _ in range(num):\n",
    "            self.hidden_layers.append(Dense(16, activation='relu', kernel_initializer=He_initializer))\n",
    "            self.hidden_layers.append(Dense(4, activation='relu', kernel_initializer=He_initializer))\n",
    "        self.u = Dense(10, activation='softmax')  \n",
    "    def call(self, state):\n",
    "        x = self.h1(state)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.flatten(x)  \n",
    "        out = self.u(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "\n",
    "    numbers = [50]\n",
    "    for num in numbers:\n",
    "        exec(f'he_acc128_{num} = []')  \n",
    "        exec(f'he_loss128_{num} = []')  \n",
    "        for _ in range(1):  \n",
    "            loss_list1 = []\n",
    "            val_acc_list = [] \n",
    "            val_loss_list = [] \n",
    "            \n",
    "            model = Burgers(num=num)\n",
    "            model.compile(optimizer=Adam(0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            \n",
    "\n",
    "            batch_accuracy_logger = BatchAccuracyLogger()\n",
    "            \n",
    "            history = model.fit(x_train, y_train, epochs=100, batch_size=64, validation_data=(x_test, y_test))\n",
    " \n",
    "\n",
    "            val_acc_list = history.history['val_accuracy']\n",
    "            val_loss_list = history.history['val_loss']\n",
    "\n",
    "            exec(f'he_acc128_{num}.append(val_acc_list)')\n",
    "            exec(f'he_loss128_{num}.append(val_loss_list)')\n",
    "            \n",
    "            loss_list1.append(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "431657d0-5aeb-4985-afe8-7e8e75b515a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC1m0lEQVR4nOzdd3iT1dvA8W/SSSer7FJ2AdnIEhkqQ1G2IrIERERxIwrIHuICwfF7FWWIoqhMQUVApsyyBNmjUKCMFujezXn/SBObNm3TNGnS9v5cV642z3Nynjtp2tw9U6OUUgghhBBCiCJP6+gAhBBCCCGEbUhiJ4QQQghRTEhiJ4QQQghRTEhiJ4QQQghRTEhiJ4QQQghRTEhiJ4QQQghRTEhiJ4QQQghRTEhiJ4QQQghRTLg6OoCiSqfTER4ejq+vLxqNxtHhCCGEEKKYUkoRGxtLlSpV0Gpzb5OTxM5K4eHhBAYGOjoMIYQQQpQQV69epVq1armWkcTOSr6+voD+Rfbz83NwNEIIIYQormJiYggMDDTmHrmRxM5Khu5XPz8/SeyEEEIIYXeWDP2SyRNCCCGEEMWEJHZCCCGEEMWEJHZCCCGEEMWEJHZCCCGEEMWEJHZCCCGEEMWEJHZCCCGEEMWEJHZCCCGEEMWEJHZCCCGEEMWEJHZCCCGEEMWEJHZCCCGEEMWEJHZCCCGEEMWEJHZCCCGEEMWEJHZCCCGEENa4ugZ+bworS+m/Xl3j6IgksRNCCCFECWFpImZJuatrYHd/iDoBuiT91939HZ7caZRSyqERFFExMTH4+/sTHR2Nn5+fo8MRQgghip+ra+DEDIg5B371oPE0COxnXTlDIoYGUP997bBaX1YpSE+Cyz/Cweeylwt8EjzKQtJt/e3uIdClZAlEA6WbQI9jNn0Z8pNzSGJnJUnshBBCiCxsmYiFrYa/nyRbgtV4BlTo+F+527vgxLTs5eq8AL71IC0e0uLg4mJIuZM9Fq0buPpAaiyotIK/BlpPGJhY8HoykcSuEEhiJ4QQQmSSU4tY83lQ6ZH/yt38C46Oy16uai9wKQWJ1yHhOsRfzjjvJDQu0GgqeFbQ346+DXGXMI3R8S12rja9shBCCCEcz5YtZzmVq9YX4q/AvSNw9yicXZhRWJl+PTouhyCzlLv+q4VPTgP+Df67G30a8wmgFmo8A67e+ha50O8h+Xb2unzqQKdfwc0X3Pxgy4P68XJZEzb/RtB4qunDzSWyjadZ+DzsQ1rsrCQtdkIIIWymMMeS5VXugR+gcndIT9SPObu+AY68kalcBldvfTenJTwr/fd90k3zZTQu0OxD8KoGXlXhwCiIOUueLWK/NzWfiGUtl+PrsgYC++a/nKHsiZn6OP2CM34eWcrYgHTFFgJJ7IQQQuTJkkQsdAXsG0K2RKL+m1C2FaADpYM7B+Dc52RLsCo+Au6lISUKUqMyZmlmHdSfQesBGq3+lpaor7sgtG7gfx+UaQ43/oTEGxSLRKyQEjZLSWJXCCSxE0KIYqgwWs4qPgJaV0i4pr+lRtv/eVlD46If85YWZ/681h2eigEXD/19ScTsRhK7QiCJnRBCFCGF0YXZaAp4VIDYc/rbre05t5xZRAsVO+tb19DCza2YbWHTuELLBeBWWt9yd/g184P6/RrAQ3/oW//QwfYe+jjNjSV77Ig++QTLW9hAEjE7kcSuEEhiJ4QQTqAgCVuj6eBbRz/mK+kmXPhG35WZlUspKN1Yn0BpXODuEUi3cGyZORpXaL0IvAOhVDX4+ymIPonTdmHmp4VN2IUkdoVAEjshhLCjgiRs9V4B7+r/LSR7dQ2kxRZC0Bqo1lu/dppfPTg517LlMIpCF6a0sDmUJHaFQBI7IYSwQkEStsAnwaOcPllLvg13QgrY1anRd3V6VtLfrvwISbfIloh519B3dap0/e3IOEi4mr2ctQmb8XWRBEuYJ4ldIZDETgghMilQwvaUfg2xhGv6hCnmLAWbrZmxfplHxkKy577QL3rrzC1nQuRCErtCIImdEKLYy88MUXOJTrMPwCsQYs9D7AW4uhrSE6yPR+Oin6DgWUGftB17x7ZdncbnLC1nwrlIYlcIJLETQhRrOSVDtZ4D//qQngy6ZP3XnPbgtJTGBRpPz1iYNhBCxpqfrVkYCZsQTkgSu0IgiZ0QwukUZA22qj0h+pR+xue9I3BxScFa1wwCOuhnnvrWhfNfOm5smhBFmCR2hUASOyGEU8ltDbZqffVJWkoUhP1ifnsojSuoNAsupIUag/SL0mo99V9z2oNTEjYhbEISu0IgiZ0QosAKusuBUvpZnPGX4e+nISEs+2M1rqDRgC4173jc/KBMCyjbQp8AJlzD4kVpJWETwm4ksSsEktgJIXJUkBmizedBQHt9C1taon73gjMfk62FrVRV/bi29CTL49K46JfrMEfrDk8nZuxykEt8OS1KKwmbEHYjiV0hkMROCGFWTglR1T7gURaSI/W3u4cKuAabgUY/6SD5rpndEDT6sW0Pb9VvNeXqA380s/32UEIIu8pPzuFaSDEJIUTRZ64lrlpfiL+iT9TuhMD5LzIKK9Ov19dZfh3vGuDqpd/K6u4RTJOwDFo3ePy0fhapi3suS468r9+6yqDxNPPlGk/Lfo3Afua7hoUQTkta7KwkLXZCFCOWdJ1eWQV7niJbl6irr2XbVWlcoMlM8Civvx1927I12GQDdiFKPOmKLQSS2AlRTGRr6coQ0B60Hv9tX5WUddZnJlo3faJV9n64/pvjdjkQQhRL0hUrhBB5SY2Fm1vgwKiMA1n+x43YY1k9Wnd4Kka/7AfknIhl7eoM7KdfiiSvljNLywkhBNJiZzVpsROiCMjaxVrnRf1abdc3wO0duU9e0LhCu2//275qz0CIOYNMOhBCFDbpii0EktgJ4UCWjIm7/CPsHUS2LtbMfGpDSnTGdlg23A1BCCFsSLpihRBFkzXrv0Wd0N8PfBJcPPUTEuJDIfFGxgOyJHUu3v9toeUXDNfW2rbrVAghHEha7KwkLXZC2FhOLWItP9PvNRp7AeIu6PcwtWQWak60njAwMfu1JWETQjgpabETQjiXvFrilIJjkzDtNs34evgVy66hcYGmc8C7JvjUgv3PQvRpsnWx+gVnf6ys1yaEKCYksRNC2FdOXacN3gatK9w5CHcOQWpUznWUbqwfD+dbRz92LjGcbAmbfyNo+M5/h5rMsnwhXiGEKCYksRNC2Nfx6ZhtiTv9YZaC5iY5mJnEUL6djIkTQogcSGInhMjOkkkMOZWr3B0i98PtXfpb9IkcLqKB2iOhXGso2wpiz8Oep7FpwiZdrEKIEsapJ08kJiYyd+5cVq5cSVhYGGXLluXRRx9l1qxZVK1aNV91bdmyhQULFnDw4EGioqLw8/OjZcuWvPjii/Ttm///4GXyhCi2cprE0PprqPKY/nulIPx3CBlD9pY2LaDL4yKy/psQQliqWKxjl5SUxEMPPcT+/fupXLkyHTp04PLlyxw8eJCAgAD2799PrVq1LKprwYIFvPHGG2g0Gtq1a0dgYCBXr15l3759KKWYNGkSc+bMyVd8ktiJYkcpfavZ1s6QdCPP4rnyCoQKHfW3tCQ48hqy/psQQlinWCR2kydPZs6cObRr147Nmzfj4+MDwPz58xk3bhydOnVix44dedYTERFBYGAgOp2OLVu20KlTJ+O5Xbt20a1bN1JSUrhw4YLFiSJIYieKqKxdp/dNBLcyEP6bvgUu7mLuj9e4gkYDaHLetUHrAQOTzFxXWuKEEMIaRT6xS0lJoUKFCkRHR3PkyBGaN29ucr5p06YcP36cQ4cO0bJly1zr2rhxIz179qR79+5s2rQp2/nevXvz66+/8tNPPzFgwACLY5TEThQ5OW12n5nWTZ+YpcVlOWGm6/T3pvoZrpZssSWEEMJq+ck5tIUUU77s2bOH6OhoateunS2pA3jyyScB2LBhQ551eXh4WHTNcuXK5S9IIYqShOsQYlgPLktSp3GF2s9Dh7XQ/45+f1T9iUxfzUxiaDyN/7pWcyknhBCi0DhlYvfPP/8A0KJFC7PnDcePHz+eZ12tW7emdOnSbNu2jZ07d5qc27VrF3/++Sd169alQ4cOBYxaCAe6ukbfgraylP7r1TWQeAvOfQFbOsK6QEgKN/9YjSu0WQSBfcDN979Zp6Wb6HdpKN3E/Hg4S8sJIYQoNE653ElYWBgA1apVM3vecPzKlSt51uXv78/ixYsZNGgQDz30EA888ADVqlXj2rVr7N27l/bt27N8+XLc3d1t9wSEKEw5LQCctcvVxQvSE7I8uIA7MchyIkII4VScMrGLi9OP7/Hy8jJ73tvbG4DYWMv2i+zXrx9//PEHAwYMYM+ePcbjfn5+dOvWzaKlU5KTk0lOTjbej4mJsejaQtjd8emYXQAYpV8jrvrTUP0puBsiOzEIIUQx55RdsbY2b948unTpQseOHTl+/DhxcXEcP36chx9+mKlTp9KvX94tDnPnzsXf3994CwwMLITIhchFUiSc+iBjAWAzkyG0HtD9ADR4E7wDpetUCCFKAKdssTMsbZKQkLXbSC8+Ph4AX1/fPOvasWMHb731Fi1atOCXX35Bq9Xnso0bN2bVqlXcf//9/Pbbb/zxxx889thjOdYzceJE3nzzTeP9mJgYSe6EY9w9DOc+1++ZqkvOoZAG/OpnPyxdp0IIUaw5ZYtd9erVAbh27ZrZ84bjQUFBedb13XffAdC3b19jUmfg4uJibK3btWtXrvV4eHjg5+dnchPCauYmO+RazhPWVYdfg2HT/XBpmT6pK9MC6o3NKCyzU4UQoqRzyha7pk2bAnDkyBGz5w3HmzRpkmddhiTQ39/f7HnD8Xv37uU7TiGsktNkh9bfQEA7SLkHyXfh5mZ9y5xBwlX9V40LBA2Eei9DuTb6BYMrPiwLAAshhHDOxK59+/b4+/tz8eJFjh07RrNmzUzOr1q1CoCePXvmWVelSpUAOHTokNnzISEhANSoUcP6gIXIj+PTMDvZ4eAoCx6sAd9geOB708PSxSqEEAIn7Yp1d3fn5ZdfBmDs2LHGMXWg31Ls+PHjdOrUyWTXic8//5z69eszceJEk7r69OkDwIoVK9i4caPJufXr1/PDDz+g1Wrp21daN4SdJUXqW9Wi/yXHnR/cy4JPHSjbCvO/ngriLtkxSCGEEEWZU7bYgX6v2K1bt7J3717jAsJXrlzhwIEDBAQEsGTJEpPykZGRnD17lhs3TDcv79OnD0899RS//PILPXv25P7776dmzZqEhoYaW/HmzJlDcLCZtbyEsIWYs3DmEwj9FtKTciiUjy27zK07J4QQQuCkLXYAnp6ebN++nSlTpuDl5cW6deu4cuUKw4cP58iRI9SqVcuiejQaDT/99BOLFy+mY8eOXLhwgbVr13L58mV69OjBH3/8waRJk+z8bESJkXlSxK91YFMr2NgALnylT+rKtoTg1zMKy5ZdQgghbEujlMqhT0jkJj8b8ooSIuukiMyqPAEN3oIKHfWTHa6usWyyg6XlhBBCFFv5yTkksbOSJHYim/W1Id7M+DffYOh5pvDjEUIIUSzkJ+dw2q5YIYqM6FOw4wnzSR1AfN57GgshhBC24LSTJ4Rweom34MQ0uPg1KF0OhWSygxBCiMIjiZ0Qlri6Bk7MgJhz4FsHSjeG6xsgLU5/vlpf/SLBh1/hvzF2MtlBCCFE4ZLEToi8ZJ0UEf1vxlp06NebazEPKnTQ3/eqIpMdhBBCOIwkdkLk5Z8pmJ3p6lUduu8HTaahqrIDhBBCCAeSxE4Ic1LuwdW1cOUniDllvkzSbdOkTgghhHAwSexEyWYydq62fpxc3CW4uRl0qbk8UCZFCCGEcD6S2ImSK9vYuZP6m0HpxlD9aXDzl0kRQgghigRJ7ETJpBQcGWe4Y3rOsyI8sh38G/x3TCZFCCGEKAIksRMlT9S/cORNiL9s/nxKtGlSBzIpQgghRJEgiZ0oOZIi9AsKX/hKFhQWQghRLEliJ4onk0kRdaFsc7i2HlKj9ecD+0PFR+DQS8jYOSGEEMWFJHai+Mk2KeKE/gZQpjm0+AQqdtLfL1VRxs4JIYQoNiSxE8XPiRmYX1A4ELqHgNblv2Mydk4IIUQxIquriuJFKYg+RbakDvRj7DIndUIIIUQxI4mdKD6S7+i7YFWamZMyKUIIIUTxJ12xoni4uQ32DYPE66BxAZWOTIoQQghR0kiLnSja0lPg2ATY1kWf1PnWg+4HocNqKN0EtJ76rx3WyKQIIYQQxZ602ImiK+Yc7B0Edw/r79d+Hlp+Aq7eULaFTIoQQghR4khiJ4qOzGvTeZSH5AjQJYN7GWjzjSRyQgghSjxJ7ETRkHVtusRr+uP+jeChP8CrmiOjE0IIIZyCjLETRYPZtek0oNFKUieEEEJkkMROFA3Rp8m+Np3Sd8sKIYQQApDETjg7XTr8MxlUqpmTsjadEEIIkZmMsRPOKyUK9g6G8N8zHZS16YQQQoicSIudcE7Rp+DP1vqkzsUT2n0va9MJIYQQeZAWO+F8rq6DfUMhLQ68qkPHtfp16UCWNBFCCCFyIYmdcDzj+nRnwc0fkm/rj1d8CNr/BJ4Bjo1PCCGEKCIksROOlXV9OkNSV+UJfUudVt6iQgghhKVkjJ1wrJzWp0u4KkmdEEIIkU9WJXbx8fG2jkOUVDFnMb8+3VlHRCOEEEIUaVYldlWqVGHMmDEcOnTI1vGIkiT6DKh0MydkfTohhBDCGlYldhqNhkWLFtGmTRtatGjBl19+SUxMjK1jE8XZ3cOwtQOotIwDmkxfZX06IYQQwhpWJXY3btxg6dKltGvXjmPHjjF27FiqVKnCyJEj2bdvn61jFMXNrZ2w9SFIjoSy90ObpbI+nRBCCGEDGqVU1gFO+XL27FkWLVrEd999R2RkJBqNhgYNGjB69GiGDh1KmTJlbBWrU4mJicHf35/o6Gj8/PwcHU7RcX0j/P0UpCdBhc7QaT24yesnhBBC5CQ/OUeBEzuD1NRU1q5dy9dff822bdsA8PDwoH///owePZoOHTrY4jJOQxI7K1z+AfY9q+9+rdoLHvxJv6uEEEIIIXLkkMTOICoqipkzZ7JgwYL/LqLR0KhRI+bMmcMTTzxhy8s5jCR2FjAuPHwOPMpB4nX98RpDoO0S0Lo5Nj4hhBCiCMhPzmGzdex2797NsGHDqFq1KgsXLsTDw4NBgwbxzTff0KVLF/7991969+7NV199ZatLCmdmWHg46gTokv5L6io/Bu2+laROCCGEsIMCtdhFRkby7bff8s0333Du3DmUUtSpU4fRo0czYsQIypUrZyx78OBBunXrRvny5blw4YJNgnckabHLw+9N9Uld1jXqSjeFHsccEZEQQghRJOUn57Bqaf+tW7fy9ddfs379elJTU3FxcaFv376MGTOGLl26mH1M69atefzxx/n555+tuaQoaswuPIwsPCyEEELYkVWJXbdu3QAIDAzk+eefZ9SoUVSqVCnPxwUGBlKtWjVrLimKEl06uHpBSnKWE7LwsBBCCGFPVnXF9uzZkxdeeIEePXqg1ZbM7WalKzYHulT9zNcrP2YcMOwDm/FV1qgTQggh8sXuXbEbNmywKjBRzKWnwJ6BcG0taFwh+HW4uUXf/eoXrN9NQpI6IYQQwm6sSuzi4uK4dOkSVapUoXz58mbLREZGEh4eTu3atfH29i5QkKIISEvUz4K98Qdo3aHDaqhaPJa2EUIIIYoKq/pR58+fT/Pmzbl48WKOZS5evEjz5s1ZuHCh1cGJIiI1DnY+rk/qXEpBp42S1AkhhBAOYNUYu1atWhETE8PZs7nPcKxXrx6lS5fm4MGDVgforGSMXYaUaH1SF7EHXH2g829QoaOjoxJCCCGKDbuPsbt06RIPPvhgnuUaNGjA3r17rbmEcGbGHSXOgkYL6YngVhoe2gTl2zg6OiGEEKLEsiqxS0xMpFSpUnmWK1WqFHFxcdZcQjgrw44SxtmuGRpNlqROCCGEcDCrxtgFBgYSEhKSZ7mQkBCqVKlizSWEszoxg2xJHRoI/c5BAQkhhBDCwKrErnv37ly+fJlPPvkkxzILFy4kNDSURx991OrghBOKOUf2HSWU7CghhBBCOAGrJk9cu3aNxo0bExMTw2OPPcbo0aOpXbs2oJ8Nu2jRIv744w98fX35559/CAoKsnngjlZiJ0/83hSijmc5qIHSTWQPWCGEEMIO7D55olq1avz666/079+f33//nT/++MPkvFKK8uXL88svvxTLpK5EqzEYjmVO7DK6ZRtPc1REQgghhMhg9X5gHTp04OzZs7z//vt06dKF4OBggoOD6dKlCx988AFnz56lU6dOtoxVOIOIPfqvbmVA66lvqZNtwoQQxcisWaDV6r86YzlHsXV8jnpdnL2+AlPCKtHR0QpQ0dHRjg6l8Nw9qtQKlFqhUSrqtKOjEUIUczNnKqXR6L8WVrmZM5WC/245lXVUOUufR37Y8nXJzzUd8bo46nkUVH5yDknsrFQiE7td/fWJ3d8DHR2JEKIIc9YEK2uZnMo6qlx+nq+lbPm6ZC6f2883p/qmTlUqOVmplBSlUlOVmj7dtq9LfuoryPOwR3JX6IndvXv3VFhYmLpy5YrZW3FU4hK7eycyWuvQfy+EEFaw5AN4yhTzH5jPPafUrl1K7dyp1I4dSo0YYb7csGFKbdqk1B9/KPX770oNHmy+XOvWSj39tFJduihVubL5MoabVquUh4dSbm65lytTRql69ZQqXz73cr6+SlWooJSnZ+7l2rRR6r33lFqyRKkhQwonMXnsMaUmT1bqpZeUatQo9/hefFGpxMS8f75xcUrt369Ur16512fp7YEHlJo/X6mff1Zq1CjzZXr2VOrNN/XXzOvnMWSIPkZL36fTpuVen62Tu/zkHFbNigW4efMmkydP5tdff+XOnTs5ltNoNKSlpVlzCadW4mbF7nkGrqyEwP7QYZWjoxFCFEGzZsHUqdmPN2wIZcvCrVsQFgbJyYUfW1H35JMwYQIEB4OPT/bXesYMeP55OHlSf/vuOzh82DbX1mqhdm1wcYEzZ7KfL1sW7t3TpzzOzM0N2rUDV1fYti37+X79oGpVOHQI9u3LvS6NBnQ628WWr5zDmswxPDxcVa1aVWk0GlWtWjVVsWJFpdFo1AMPPKAqVaqkNBqN0mq1qn379qpz587WXMLplagWu6jT+nF1K9CPsxNC2IwjxpHZo1xOZdPTlTp4UKmHH7ZNSw0oFRxsWbnmzS0r9913ObeGGW5vvaXUlStKvfFG7uVGjdK3KObUmmi4jRmj1PHjSr3ySu7lOnRQavjw/L0+fn62eZ2nTNG33uVWplQpy+urVEmpOnVyLzNxolJ37ig1YULu5R54QKkBAyy77hdf6Ftxcyvj72+b18xwc2SLHdZc4KWXXlIajUbNmjVLKaXU8OHDlVarNZ7fuXOnatiwoXrwwQdVYuY22mKkRCV2e4bok7odvRwdiRDFirMP1M/vwPXMZfv313eB5tUFlvm2c6dSr75q2QdmTt2I1pbLrawzjLHL63kEBem7dvN6jcuWVapPH6U6drTN66LTKXXjhj6hz60+jcYxr0t+nseFC5a9T7//XqmzZ5WaMcOy52ELdk/satWqpWrVqmW8nzWxU0qpa9euKW9vbzVp0iRrLuH0SkxiF3NeqR+0+sQuMsTR0QhRZNhq4HVe5dLSlIqP17d0mCv3zjtK3b2rHz+UnGz5h1FO150wQamLF5U6ckSp7duVWr9eqX79cv8g9PVVqkED23wA2+M1zK2sMyXRljwPeyRYlsSXnwTLEa+Lo59HQdk9sfPw8FD9+vUz3n/uueeUVqtVSUlJJuWeeOIJVadOHWsu4fRKTGK3b4Q+qdvew9GRCFFk5PTH3tC6MXRo7h8e3t76bitf39zLabW5n8/vrVQppcqVU8rLy3Z1jhypn+Vo7nVxxgTLUNZZu70dmZjY6p+V/DxfS8sVhedREHZP7AICAkwSu3HjximtVqsuXrxoUu7JJ59UpUqVsuYSTq9EJHaxl5T6wUWf2EXsc3Q0QpiwxxgxW8Vl7kOhVi2lAgJsm4g58la5slL16+ddLnMLkbnXxxkTLGfnzIlJYbVg5XTt4vA8zLF7YteyZUt1//33G+8vXbpUabVa9dlnnxmPxcfHq8qVK5t02RYnJSKxOzBan9T91dXRkQhhwh6tNPaIy9xNq8173NnYsUodO6ZfSiK3cm+9pVREhH5pitzKTZum74qdNCn3cq+8otTJk0q9/HLu5awd45T5McUhwXJmxSXBciRneh52T+zGjx+v3N3d1e3bt5VSSt25c0f5+voqT09P9c4776hPP/1UtW7dWmm1WjV27FhrLuH0in1iF3dFqR/d9Indrd2OjkYII3uMq7IFnc6y8U0JCfZ5Hs40Ls1ZWjlKOmdKTETB2D2xO3bsmBo4cKDasWOH8dgPP/ygPDw8jEudaDQa1ahRIxUVFWXNJZRSSiUkJKgpU6aounXrKg8PD1W5cmU1YsQIde3aNavqCw0NVS+88IKqUaOGcnd3V+XKlVNt27ZVH374Yb7rKvaJ3cGX9Endls6OjkSUMLl9GOXVOlSlilL33adfJDa/rUgFiW/nTv3yC3m11tlzALkjy+W3rBAifxy2pdiVK1fU//3f/6n33ntPrVq1SqUYRsxaITExUbVt21YBqnLlymrAgAGqdevWClABAQHZxvPl5ffff1deXl5Ko9Goli1bqoEDB6quXbuqSpUqqdq1a+c7vmKd2MVfU+pHd31id3Obo6MRxYQ1A6CnTFHq77+V+vhjpZ56Ku/EydJb1nFf1sb34otKPfrof/c9PZV68MH8JZPOPFA/P+XyW1YIYTm7J3b//POPOnHCvttKvfvuuwpQ7dq1U7Gxscbj8+bNU4Dq1KmTxXWdPn1aeXp6qoCAALVnzx6Tc+np6SokJP/LeBTLxC5stVK/NflvwsSG+vr+JSEKKK/WnMTEvNcvs+Q2eLBSf/2l1PPP5122VSulli9XKinJstam3FoLXV31C85ev27Z8xVCiPywe2Kn0WjsuqNEcnKy8vf3V4A6cuRItvNNmjRRgDp06JBF9T322GMKUL/99pvNYix2iV3Y6oy9YDX/7Qm7Av1xIQogp4Tovvv0+2BWrJh3Ela/vlJz5+rXTctpooClY8SaNVPK3f2/+97e5suNH6/fMWH1aqV69Mg9vtdfN/+8pfVKCGELdk/sypUrpwYNGmTNQy2ybds2BeTYRTpz5kwFqGnTpuVZV1hYmNJqtTafnVvsErvfmmRP6lZolPqtqaMjE0WYJbNErek6LegYsdu3lZozx3ZbL5nr2hVCCFvJT86htWYz2rZt23LixAlrHmqRf/75B4AWLVqYPW84fvz48Tzr2rFjBzqdjgceeIC0tDR+/vlnXnvtNV5++WW+/PJL7t27Z7vAi7KYc4DKclBBzFlHRCOKgTt3zG/4nplGo99Qe8KE3MvNmGF6f8oUmDlT//iZM/X3zcmpXEAATJoEsbF5P4+2beG++/IXnxBCOIpVid20adM4e/Ys8+bNs3U8AISFhQFQrVo1s+cNx69cuZJnXadOnQLAx8eHDh068PTTT/Ppp5/yxRdf8OKLL1KnTh22b99uo8iLML96gCbLQQ34BTsiGlGEzJoFWq3+K+iTpVmzoFatvB87Ywa0bAlz5+oTL3NyStymTAGdLuekzpJyeSVkM2fCvn3w77/5j08IIRzB1ZoHnT59miFDhvD222/z/fff8/jjj1O9enU8PT3Nlh82bFi+6o+LiwPAy8vL7Hlvb28AYi34d9vQIvfNN9/g4+PDDz/8wKOPPkpERASzZs3i+++/p2/fvpw8eZKqVavmWE9ycjLJycnG+zExMRY/nyKh0VT4+8lMBzSAgsbTHBWRKAJmzfqvVW7qVNi7V98CFxmpP9a0KTRqBCtWZH9s1oTI8H3mVj57J03mrulM8QkhRL5Z09ebea06w02r1Wa7GY7n1/PPP68A9e6775o9f/78eQWounXrWlwXoH766ads51u1aqUANWnSpFzrmTZtmrGezLdiM8bu5raMcXVapX700I+tC1vj6KiEE8tt/FzdukqtXKlUerr5srbYRsqWnD0+IUTJlp8xdla12E2dOhWNJmu3ne34+PgAkJCQYPZ8fHw8AL6+vhbX5ePjw1NPPZXt/IgRIwgJCWHnzp251jNx4kTefPNN4/2YmBgCAwPzvH6Rce5z/dc6o6H1/zk2FuH0MrfUmTN4MDz99H/3Da1a06bpuz9za+WaMqXwW8GcPT4hhLCUVYnd9OnTbRyGqerVqwNw7do1s+cNx4OCgvKsy1CmevXqZpPRGjVqAHD79u1c6/Hw8MDDwyPP6xVJ8WFwbZ3++3pjHRqKKBqm5dFDP2NG9jLOnhA5e3zCtpRSpKenk5aW5uhQRAnl6uqKi4uLzRvKrErs7K1p06YAHDlyxOx5w/EmTZrkWVfz5s0Bcpz9evfuXeC/lr0S6fyXoHRQ8SEo3cjR0Qgnt38/lC2rn/WaE5klKpyVUoqoqCgiIiJIT093dDiihHNxcaFChQr4+/vbLMFzysSuffv2+Pv7c/HiRY4dO0azZs1Mzq9atQqAnj175lnXAw88QLly5bh58yZnz54lONh0lqehC9aQAJY46Ulw8Wv99/VedmwswqklJcH06fDRR/pZpj4+kDHPyYRMKBDO7ObNm0RFReHn54efnx+urq52HVokhDlKKdLS0oiJieHGjRskJiZSuXJlm9RtVWL38MMPW1xWo9Hw119/5at+d3d3Xn75ZebMmcPYsWPZvHmzcSbs/PnzOX78OJ06daJly5bGx3z++ed8/vnn9O3bl7lz5xqPu7q68uabb/Luu+8yduxY1qxZg5+fHwBbt25l2bJlaDQaXnjhhXzFWGxc+RmSI8ErEKr2cnQ0wonMmvXfmLNHH4XhwyFj9SCGDIGFC+GLL2SWqCg60tPTiY6OJiAggPLlyzs6HCHw9fXFw8ODyMhIKlSogIuLS4HrtCqx27FjR55lNBoNSimr/xOaPHkyW7duZe/evdStW5cOHTpw5coVDhw4QEBAAEuWLDEpHxkZydmzZ7lx40a2usaPH8/27dvZunUr9erVo23btkRGRrJ//37S09OZM2cOrVu3tirOIs8waaLui6B1ygZc4QBZlzGZNk0/X7RiRfjqK+jdW38uP5MOhHC01NRUlFLGhgIhnIG3tzcRERGkpqbaJLGzaoHi0NBQs7eLFy+yY8cOJk2ahJeXF+PHj+fSpUtWBebp6cn27duZMmUKXl5erFu3jitXrjB8+HCOHDlCLUtWP83g5ubG77//zgcffED58uX5888/OXHiBJ06dWLDhg1MmjTJqhiLvMiDcDcEtO5Qe5SjoxFOwtyMV6WgcWM4efK/pM7A0oWChXAW0vUqnImt348apVTWfaRsYtu2bXTv3p2ff/6Zvn372uMSDhUTE4O/vz/R0dHGrt0iZ+9QuPw91BwG7b51dDSikGTuYs2cjN27By++CD/9lPNjpatVFGVJSUmEhoZSs2bNHBfUF6KwWfK+zE/OYbfEDqBdu3bodDoOHDhgr0s4TJFP7BJvwfrqoEuB7iFQ7n5HRyQKQdbWuFGjoEoV+PNPCAnRt7zlRqPJu4wQzkoSO+GMbJ3YWdUVa6lq1apx8uRJe15CWOviN/qkrlwbSepKCHNdrN98o2+FO3BAn7AFBORehyxjIoQoznbs2IFGo2HZsmWODsVqdkvsEhMTCQkJkf+KnJEuDc5n7C4hS5yUCHntFNGnD1y9Crdvy2b3QhQXhiQl883Hx4eWLVuycOFCWcevmLJqGmRYWFiO5+Li4jh37hzz5s3j6tWrPPPMM1YHJ+zk2jpIvA6eFaB69m3WRPESH597Ugewfj2sXav/Xja7F6J4eeaZZ+jRowdKKcLDw1m2bBmvv/46J0+eZNGiRY4OT9iYVYldjRo18pzFoZQiODiYjz76yKrAhB0ZljipPRpciuk2aQLQj50bMybvclm7WGUZEyGKjxYtWjBkyBDj/RdffJEGDRrwzTffMGvWLCpWrJjtMbGxsRbtxy6cj1VdsR07dszx1qVLF4YOHcrixYs5evSozVZSFjYSdQJu7wSNC9QtoYsyF1OzZoFWq/96+7Z+EeFHH4XLl6F6dRg82PzjcmqNk2VMhCie/Pz8aNeuHUopLl26RI0aNejcuTNHjx6le/fu+Pv7m2zZuWvXLrp27Yq/vz+lSpWiRYsWLF68OFu9nTt3pkaNGly6dInevXvj7++Pn58fffv2Nbv0WXx8PBMnTqR27dp4eHhQqVIlhg0bxpUrV0zK6XQ6FixYQJMmTfD19cXPz4/g4GCee+45UlNTTcoeOnSIvn37Ur58eTw8PAgODmbOnDlm9wRev349zZs3x9PTk8DAQKZMmZKtvqLIbgsUCyd17gv912p9wauaY2MRNpN1QeG5cyExUZ/ovfqq/ryPDwQHSxerEHZzdQ2cmAEx58CvHjSeBoH9HB1VNkopLly4AGDcgSMsLIyHH36Yp556iv79+xOXsV/ghg0b6Nu3L5UqVWLcuHH4+vqycuVKRo0axaVLl5gzZ45J3fHx8XTu3Jk2bdowd+5czp8/z//+9z/279/P0aNHqVSpEqBfLLp79+7s2bOHJ598knHjxnH+/Hn+7//+j82bN3Po0CGqVdN/Rs2ZM4epU6fSs2dPxowZg4uLC6Ghofz6668kJyfj5uYGwG+//Ua/fv2oU6cO48aNo2zZsuzbt4+pU6dy7NgxfvnlF2Oca9eupX///tSoUYOpU6fi6urK0qVL+e233+z74hcGJawSHR2tABUdHe3oUCyXfFeplV5KrUCpWzsdHY2wkZkzldIvIWx6q1RJqYMHzZfXaPRfhShJEhMT1alTp1RiYqLpCZ1OqdS4gt1CV+j/tq7QmH4NXVGwenU6q5/v9u3bFaBmzJihIiIi1O3bt9U///yjRo0apQDVtm1bpZRSQUFBClBff/21yePT0tJU9erVlb+/v7p+/brxeHJysnrggQeUVqtV586dMx7v1KmTAtRrr71mUs+aNWsUoF544QXjsUWLFilAjR8/3qTsxo0bFaCGDBliPNa8eXPVoEGDXJ9rYmKiqlixourQoYNKTU01OTd//nwFqO3btxufV2BgoCpXrpyKiIgwlouKilLVq1dXgFq6dGmu17OlHN+XmeQn57CqxS4uLo5Lly5RpUqVHPfbi4yMJDw8nNq1a8v2Lc7i0jJIT4DSjSGgg6OjETaQ22zXmzdh0yZo1cr0+JQp0konhIn0BPjZx0aVKdOve3MYA2GpAXHgWrDP0GnTpjFt2jTjfa1WS69evUwmTpQtW5YRI0aYPO7w4cOEhYXxxhtvUKVKFeNxd3d33n77bfr06cP69et56623TB43YcIEk/t9+/YlODiYdevW8eWXXwL6FjOtVsvEiRNNyj7++OM0a9aM9evXo9Pp0Gq1+Pv7c/HiRf7++28efPBBs89xy5Yt3Lp1i7lz5xIVFWVyrkePHrz55pts3ryZzp07c/jwYa5evcpbb71lksP4+/szZsyYIr8blVVj7ObPn0/z5s25ePFijmUuXrxI8+bNWbhwodXBCRu5ugZ+bwpHxunvl39Av9KsKNKSkvKe7Zrpb7kQooQaPXo0W7ZsYevWrezbt4+IiAjWr19vMmmidu3a2fYpDQ0NBeC+++7LVqfhWNaxc6VLlzZ2t2bWoEEDbt26RXx8vLHuKlWqUKZMGbN1x8bGEhkZCcB7772Hp6cnHTp0oGrVqgwePJgffviBlJQU42NOnz4NwMiRIwkICDC51a9fH4Bbt26ZxGw4nlnDhg2zHStqrGqx27BhA3Xq1KFNmzY5lmnTpg21a9dm3bp1RT77LdKuroHd/QENxv8gL3wFlbs55dgPkV3WLcB0OlixAiZPzvuxsqCwEBZw8dK3jBXEn20h+iT/tdgBaMC/EXTfV7DYCqhu3bp06dIl1zJeXgW/jr20a9eOixcv8ueff7J9+3a2b9/ODz/8wOzZs/n7778pW7YsKmMTrY8++ohmzZqZrSdzq2NxZlVid+nSpRybQzNr0KABe/futeYSwlZOzMAkqQP9/RMzJbErArJOirhwAf75R38DqFpV39W6bl32x8rECCEspNEUuLuTJjOy/BOd8bXJjILX7SC1atUCMLuD1KlTp0zKGERFRXHz5s1srXanT5+mQoUKxqFZtWrVYtOmTURFRVG6dOlsdfv5+Zl0k/r4+NC/f3/69+8PwP/+9z/Gjh3L4sWLGT9+PHXr1gXA29s7zyTWEPOZM2dyfF5FmVVdsYmJiZQqVSrPcqVKlTLOrBEOEnMO06QO/f2Ys46IRuSDufFzy5frkzo/P/3M1/Pn9QsLZ90tQpI6IQpZYD/osBpKNwGtp/5rhzUQ2NfRkVmtRYsWVK9enaVLl3Lz5k3j8dTUVD766CM0Gg29e/fO9rj333/f5P7atWs5e/Ysffr0MR7r06cPOp0uW9k//viDo0eP0qtXL7RafYpi6JLNGhvA3bt3AejevTsVKlTg/fffNx7LLDExkdjYWABatmxJtWrVWLp0qUndMTExxjGARZlVLXaBgYGEhITkWS4kJKTENH06Lb96+rXrsrbY+QU7KiJhgby2AHvpJcg8PlkWFBbCCQT2K1Y9IS4uLnz++ef07duXVq1aMXr0aHx9ffnpp5/Yv38/kyZNMraUGZQvX541a9YQHh5O586djcudVKxYkenTpxvLDR8+nG+//ZYPPviAy5cv07FjRy5cuGAs+9577xnLNmjQgLZt29KmTRuqVKnCjRs3WLRoEe7u7gwcOBDQt9QtX76cPn36EBwczMiRI6lTpw5RUVGcOXOGNWvWsHbtWjp37oyLiwuffPIJAwYMoHXr1jz//PO4urqyZMkSypUrl+vuWkWCNVNzX3nlFaXVatX8+fNzLLNgwQKl0WjUSy+9ZM0lnF6RWe4kbHXG1HtMp+CHrXF0ZCIXGo35JUwMN43G0REKUfRYsqxEcWJY7uSjjz7KtVxQUJDq1KlTjud37NihunTponx9fZWHh4dq1qyZ+uabb7KV69SpkwoKClIXL15UvXr1Ur6+vsrHx0f16tVLnT9/Plv5uLg4NWHCBFWzZk3l5uamAgIC1JAhQ9Tly5dNys2dO1d16NBBBQQEKHd3d1WtWjX15JNPqsOHD2er88SJE2rw4MGqSpUqys3NTVWoUEG1a9dOzZw5U925c8ek7OrVq1XTpk2NdU6ePFlt3ry5yC93olFKZe2ny9O1a9do3LgxMTExPPbYY4wePZratWsD+tmwixYt4o8//sDX15d//vmHoKAgmyajziAmJgZ/f3+io6Px8/NzdDi5+zUY4s6Bxg38G2Ysmll0uwdKgrxa7KSrVYj8S0pKIjQ0lJo1a+Lp6enocIqdzp07c/nyZS5fvuzoUIoUS96X+ck5rOqKrVatGr/++iv9+/fn999/548//jA5r5SifPny/PLLL8UyqStSUmMgPmNZml4XwLu6Y+MRFskyHtmEJHVCCCFyYlViB9ChQwfOnj3L119/zV9//cXVq1cB/fi7Ll26MGrUKLPr04hCdmsnqHTwqSNJXRFx4AA895z++wcfhL///u+cJHVCCCFyY3ViB1CmTBnefvtt3n77bVvFI2zt1l/6r5UecWwcwiJXr0Lv3pCcDL166We8zpkjkyKEEEJYpkCJnSgCbm3Tf5XEzunFx+uTulu3oHFj+P570GplCzAhRNGwY8cOR4cgsHIdu23bttGvXz92796dY5ldu3bRr18/du3aZXVwooCSbmcsdQJU6OzQUETudDp49lk4ehQCAmDDBvD1dXRUQgghihqrEruvvvqKLVu25LhtB0CzZs3YvHlzsVjsr8i6mdFaV7opeAY4NhaRq+nTYfVqcHfXd7/KnCMhhBDWsCqxO3jwIM2bN8c3lyYFPz8/WrRowYEDB6wOThSQjK8rElau1C9vAvDVV9C+vWPjEUIIUXRZldjdvHmTwMDAPMsFBgZy48YNay4hbOFmRmJXURI7ZzRrln4M3dCh+vtvvQXDhzs0JCGEEEWcVZMnvL29uXXrVp7lbt++LYtAOkpcKMSHgsYVKnR0dDQii8wLEKelQb16kGXLRCGEECLfrGqxa968OXv27Ml1P7WwsDB2795N06ZNrQ5OFIChta58G3DzcWwswoS5XSXOnYNMWyMKIYQQVrEqsRs5ciTJyck88cQTHDp0KNv5Q4cO0bNnT1JTUxk5cmSBgxRWuCXdsM4ot63Cpk79b6ydEEIIYQ2r9ooFGDBgAKtWrUKj0dC0aVOTvWL/+ecflFL07duX1atX2zRgZ+HUe8UqBWsr6Zc76bJTumKdiFar//HkRKPRL30ihLA92StWOCNb7xVrVYsdwMqVK5k5cyb+/v4cO3aM1atXs3r1ao4dO4a/vz8zZszg559/trZ6URDR/+qTOhcvKNfW0dEI9Mnchx/mXW7GDPvHIoQQheXy5ctoNBqmT5/u6FBKDKsTO61Wy+TJk7l16xZ79uxh5cqVrFy5kj179nDz5k2mTJmCi4uLLWMVljKsX1ehA7i4OzYWQUICDBoE77yjT/BatjRfTvaBFULY0qRJk9BoNCxZsiTbOaUUnTt3xsPDg3///dcB0Ql7KfCWYm5ubrRr14527dplO3f8+HG+++47Pvroo4JeRuSHjK9zGpcvQ9++cOwYuLrCp5/CmDEwe7bpWDtJ6oQQtjZ9+nQ2bNjAm2++Sbdu3ahWrZrx3IIFC9i5cydz586lUaNGdoshKCiIxMREXF1lB9PCYnWLXU7Cw8P56KOPaNq0Kc2bN2f+/Pm2voTIjS4Nbu/Ufy8LEzuEYX26kSPh/vv1SV2FCrBtG7z4on4c3ZQp+mROo5GkTghhH+7u7nz77bfEx8fz3HPPGY+fPXuWd999lzZt2jB+/Hi7xqDRaPD09LR5YhcbG2vT+ooTmyR28fHxLF++nK5duxIUFMSECRM4ceIEAQEBvPTSS7a4hLDU3UOQGgPuZaBMM0dHU+IYZr0qBUuXwp07+q7XQ4egQwfTslOm6CdKSFInRPFh+MfOWWa4t2jRgokTJ7J582YWLVpEeno6w4YNQynFt99+azJk6qeffqJXr15Ur14dDw8PypcvT58+fTh+/LhJnW3atKFixYqkpaVlu96ff/6JRqNhwYIFQO5j7H766ScefPBBfH198fLyok2bNqxatSpbOY1Gw/Dhw/nrr7948MEH8fHxoWfPngV7YYoxqxM7nU7Hpk2bGDx4MBUrVmTEiBH89ddf6HQ6nn32Wf7880/Cw8P57LPPbBmvyItxt4mHQGPzBlmRi5yWMunRAyzYqEUIUcRl/sfOmZYvmjJlCk2bNuWtt97ilVde4eDBg8yZM4fg4GCTcp9//jlarZbRo0fzxRdf8Pzzz7N7927at2/P+fPnjeWeffZZbt++zaZNm7Jda/ny5bi6ujJo0KBcY5o8eTIDBw7E19eXWbNm8f777+Pl5cVTTz3FF198ka38oUOH6NOnD61bt+aTTz5h8ODBVr4aJYDKp8OHD6vXX39dVapUSWm1WqXRaJSbm5t64oknVI0aNZRWq81vlUVSdHS0AlR0dLSjQzG19SGlVqDU2S8cHUmJMnOmUvo/5+ZvM2c6OkIhRGJiojp16pRKTEw0Oa7TKRUXV7Db5Mnmf/cnTy5YvTqdbZ77sWPHlJubmwLUgw8+qNLT07OViYuLy3bs1KlTyt3dXb344ovGY3fu3FHu7u7qqaeeMikbExOjvLy8VM+ePY3HQkNDFaCmTZtmPHb48GEFqIkTJ2a7Xu/evZWvr6+KiYkxHgMUoLZs2ZKv51xU5PS+zCw/OYdFnd5Xr15lxYoVfPfdd5w5cwaVsRBX69atGTJkCAMHDqR8+fJ06NAh190ohJ2lJULEXv33Mr6uUE2blvd56XIVwjklJICPnTbomT1bf7NWXBx4exc8Dn9/fzw8PEhNTaVHjx5otdl7dLwzLqSUIjY2lpSUFAICAggODubAgQPGcmXLlqVnz55s2LCBqKgoSpcuDcCqVatISEjg2WefzTWWFStWoNFoePbZZ4mMjDQ516tXL9avX8++ffvo1q2b8XjTpk3p0qWLtU+/RLEosatRowag/2HXrl2bwYMHM2TIEOrUqWPP2ER+Re4BXTKUqgq+9RwdTYkyY0bOO0oYzgshhCMopRgxYgQpKSk0aNCA2bNnM2DAAOPGAgZHjx5lypQp7Nixg/j4eJNzNWvWNLn/7LPPsnr1an7++WdGjx4N6Lthy5Qpk+f4t9OnT6OUon79+jmWyboffb168plmKYsSO6UUGo2GKlWqMGHCBAYMGICvr6+9YxP5ZRhfV+kR/XRLUWjefRc++wwiIrKfk1mvQjg3Ly99y5i13n8/91a5yZNhwgTr6vbysu5xmX322Wfs2LGDOXPm0Lt3b1q0aMHIkSPZsWMHmozPirCwMDp27Iifnx9TpkwhODgYb29vNBoNr7/+OnFZXqDHHnuMgIAAli9fzujRowkLC2Pnzp2MGTMGd/fc10815BR//PFHjuvd3nfffSb3vWzxQpQQFiV2Y8aM4eeffyY8PJzRo0fzyiuv0LNnTwYPHkyPHj1kfRpncVPWr3OU33/XJ3UeHpCc/N9xSeqEcH4aTcG6O2fNAnd38632jv4bcP78eSZOnEirVq145513cHFxYfr06UyaNInPPvuMV199FYC1a9cSFxfHr7/+ykMPPWRSx507d/Dw8DA5ZpggsXDhQi5dusSPP/6IUirPbliAunXrsmnTJqpXr06DBg1s92QFYOGs2P/973/cuHGDNWvW0KdPH5RS/PLLL/Tt25fKlSvz8ssvs2/fPnvHKnKTEgX3Duu/l/F1hc6wBverr8r6dEKURIa1KTNz9N8AnU7H8OHDSU9PN1na5O233+b+++9n4sSJXLx4EcB4TmXZzPrrr7/m5s2bZus3JHHLly/nu+++Izg4mDZt2uQZ19ChQwH9zhjp6enZzmfthhX5ZM0MjqioKPXVV1+pBx980DgzVqvVGm+nT5+2ptoixelmxV5dp58NuyHY0ZGUOPv26We/ubkpde2ao6MRQuTEktmHBTVzplIajXPMhP/www8VoD744INs5/7991/l7u6uOnbsqHQ6nbpw4YLy8vJSVapUUe+99576v//7PzVkyBBVtmxZVbt2bRUUFGT2Go0bN1Z+fn4KUO+991628+ZmxSql1PTp0xWgGjVqpGbMmKG+/vprNXPmTNW7d2/l5uZmUhZQzz77rLUvg9Oz9axYqxY68/f3Z/To0ezevZuLFy8yc+ZM6tSpg1IKpRT33XcfzZo148MPP+TKlSs2S0JFLqQb1mEMrXVDhkDVqo6NRQjhWM6y8Pjp06eZMmUKbdu2Zdy4cdnO33fffUyfPp1du3bx2WefUbt2bf744w9q1qzJe++9x4QJE7h79y47d+402Yosq2effZaYmBi0Wi1DhgyxOL5p06axceNGqlSpwoIFCxg7diyLFi0iOTmZTz/91KrnLPQ0SmVpdy2AkJAQli9fzs8//0xExihyrVZrdnXqoi4mJgZ/f3+io6Px8/NzdDjw230QfQo6rIbAfo6OpsQ4fx6Cg/UrVp08CQ0bOjoiIUROkpKSCA0NpWbNmnh6ejo6HCEAy96X+ck5bLo1QatWrfjss88IDw9nw4YNPPXUU3nOjhE2kHhDn9ShgQqdHR1NiTJvnj6pe+IJSeqEEEI4nl2ms7q4uPD444/z+OOPy0a9heHmNv3Xsi3Ao6xjYylBbt2CZcv037/9tkNDEUIIIQAbt9iZI+vdFYJbhvF1Dzs2jhLm88/1S5u0aQMPPujoaIQQQohCSOyEnSklEyccIC4ODPtUv/22rActhBDCOUhiV5RdXQMbG0BCxv68KXccG08JsmQJ3LsHdetC796OjkYIIYTQky0jiqqra2B3fyBTU9HeweDiKbNi7SwtDebP138/bhzksCOOEEIIUeikxa6oOjEDfVKXebUaDZyYmcMDhK388gtcuQIVKsCwYY6ORgghhPiPJHZFVcw5TJM69PdjzjoimhJDKfjwQ/33r74KpUo5Nh4hhBAiM0nsiiq/eph0w4L+vl+wI6IpMbZuhWPH9BuGv/iio6MRQgghTBV4jF1YWBg3btwgOTk5xzIdO3Ys6GVEVo2nZYyxM8jolm08zVERFXuzZsHUqfrvR42CsrJkoBBCCCdjdWK3ZMkSZs2aRVhYWJ5l09PTrb2MyElgP6g/Ds7MAzRQuok+qQvs6+jIiqXMSR3IhAkhhBDOyarEbunSpYwaNQqARo0aUa9ePVmI2BHcy+i/1hwG7ZY5NJTiLGtSB/pZsaVLO36jbyGEECIzqxK7+fPn4+rqyqpVq+jVq5etYxKWMkyUkHF1dmMuqTMwHJfkTggh9Dp37szly5e5fPmyo0NxuGXLljFixAi2b99O586dC+26Vk2eOH/+PB07dpSkztFiz+m/+tZzbBzF2LQ8hizmdV4IIRwtJiaGWbNm0aJFC3x9ffHy8qJhw4aMHz+eW7du5bu+ZcuWsWDBAtsHKmzCqsSubNmylC9f3taxiPxQmZY28ZPEzl5mzCjYeSGEcKRz587RtGlTpk2bRq1atXj//fdZsGABbdu2ZeHChdx3333s27cvX3VKYufcrOqK7d27Nxs3biQ1NRU3NzdbxyQskXwHUqP03/vUcWgoxdmUKfoc2lzL3MyZ0g0rhHBeCQkJ9OzZk+vXr7NhwwYef/xx47nRo0fz0ksv0aVLF3r37s2JEyeoWLFijnUppYiPj8fHx6cwQhcFYFWL3XvvvYe3tzcjRozg3r17to5JWMLQDetVHVxllVx7Gjgw+zFJ6oQQmcWHh3P31Klst/jwcIfFtHjxYs6dO8frr79uktQZ3H///bz33ntERETw0UcfGY/v2LEDjUbDsmXL+OKLL2jYsCGenp58/PHH1KhRg507d3LlyhU0Go3xtmPHDpO6w8PDeeaZZyhTpgxeXl50796dc+fOZYshMjKSsWPHEhgYiLu7O4GBgYwdO5Y7d7LvfX758mX69++Pn58ffn5+9O7dm9DQUGrUqGF2DNs333xDixYtKFWqFP7+/nTr1o2///47WzmNRsPw4cPZt28fnTp1wtvbm3LlyjFq1Cji4uJMyp45c4aXXnqJ++67z9it3bJlS7755pucfgyFzqoWu3HjxtGwYUN+/PFHfvvtN1q2bEm1atXQarPniRqNhsWLFxc4UJGFIbGTbli7M/RSVK8OV6/qu18lqRNCGMSHh7Ph8cfRpaRkO6d1d6fnb7/hXaVKoce1atUqQN86l5Phw4fz+uuvs3r1aj7++GOTcwsWLODOnTs8//zzVKpUicDAQJo1a8bEiROJjIzkk08+MZZt0KCB8fv4+Hg6duxI27Ztee+99wgNDWXhwoX07t2bf//9F5eM9aKio6N54IEHuHDhAiNHjqRFixYcPXqU//u//2Pbtm0cPHjQuOLGnTt36NChA7du3WLMmDE0aNCA3bt389BDDxEfH5/teb3zzjt8+OGHtG7dmvfee4/Y2FgWLVrEQw89xPr16+nRo4dJ+WPHjvHEE08wYsQIBg0axI4dO1i8eDFarZZFixYZy+3YsYNdu3bxxBNPULNmTeLj4/nll194/vnniYiIYOLEiZb+eOxHWUGj0Vh802q11lzC6UVHRytARUdHOyaAoxOVWoFSB19yzPVLkBdeUAqUeustR0cihCiIxMREderUKZWYmGhyXKfTqdT4eKtvtw8fVisaNszxdvvwYavr1ul0Vj/fsmXLKl9f3zzLNW7cWAEqNjZWKaXU9u3bFaDKlCmjbt26la18p06dVFBQkNm6OnXqpAD1wQcfmBz/8MMPFaA2bdpkPDZp0iQFqC+++MKk7Oeff64ANXnyZOOx8ePHK0B9//33JmUNxzt16mQ8dubMGaXRaFT79u1VcnKy8fj169eVv7+/CgoKUmlpacbjgNJoNGr//v0mdffo0UO5uroaXxellIqLi8v2nNPT01WnTp2Un5+fSklJMR5funSpAtT27dvNvVRGOb0vM8tPzmFVi9327dttkVOKgpAZsYXG0GLXrp1j4xBC2Ed6YiI/t2plt/q3DB1q9WMHhITg6uVl1WNjYmKoVKlSnuX8/PwAfQta5jF0w4YNo0KFCvm+rlar5dVXXzU59vDDDwP6VTW6d+8OwNq1awkICMjWovjCCy8wY8YM1q5dy6xZswDYsGEDlStX5plnnjEp+9Zbb5l0IwOsX78epRRvv/027u7uxuNVqlRhxIgRLFiwgKNHj3L//fcbz7Vr1442bdpki/n333/n8uXLNGrUCABvb2/j+aSkJOLj41FK0a1bN3bu3MmZM2do3Lix5S+WHViV2HXq1MnWcYj8kq7YQhEbC//+q/9eEjshRFHi5+dHTExMnuUMZfz9/U2O16tn3edLlSpV8PT0NDlWrlw5AJOxc6Ghodx///24upqmIq6urtSrV48jR46YlG3dunW2IV8VKlSgdOnSJsdCQ0MBuO+++7LFZjh26dIlk8SuVq1a2cqaizkuLo7p06fz888/c/Xq1WyPcYZ5BwXeK1Y4gNJB7Hn997I4sV2FhIBOB0FBULmyo6MRQtiDS6lSDAgJsfrx986cybVVrut331Gmfn2r6nYpZf3kuEaNGrFr1y4uXLhAnTrmV09ISEjgzJkz1KhRI9uMVy8rWwpdctlzUd/z6XwsjXnQoEFs3LiR0aNH07FjR8qVK4eLiwu///47n3zyCTqdrjDCzVWBEruUlBRWr17N7t27uX79OgBVq1alQ4cO9O/f36QJ1BqJiYnMnTuXlStXEhYWRtmyZXn00UeZNWsWVatWtbre8+fP06RJE5KSknjkkUfYunVrgeIsdAlXIT0JtG7gFeToaIo1Qzds27aOjUMIYT8ajcbq7k4AlyytU+bOF6R+a/Xr149du3bxzTff8P7775sts3z5clJTU+nXr5/F9Wo0GpvEV6tWLc6ePUtaWppJq11aWhrnzp0zaUWrUaMGFy5cQKfTmbTa3b59m6ioqGz1Apw8eZLatWubnDt16pRJmfyIiopi48aNDB06lC+//NLknDPlEVYtdwKwZ88e6taty5AhQ/jyyy/ZsGEDGzZs4Msvv2TIkCHUrVuXvXv3Wh1YUlISDz/8MLNmzSIuLo7evXsTGBjI0qVLad68OZcuXbK67tGjR5OcnGz14x0uJqMb1qcOaGU3enuS8XVCiLx4lC6NNoeGDK27Ox5ZugoLy6hRo6hTpw7z589n06ZN2c4fOXKEiRMnEhAQwPjx4y2u18fHh3v37hW49a1Pnz5ERERkWyrk66+/JiIigr59+xqP9ezZkxs3bvDjjz+alM06kxegV69eaDQaPvroI1JTU43Hb9y4wdKlSwkKCqJ58+b5jtfQqpf1ed+4caPoL3dy7tw5HnvsMeLi4mjZsiVDhgyhRo0aaDQaLl++zHfffcfhw4fp0aMHISEh1K1bN9/XmD17Nvv376ddu3Zs3rzZ2EQ8f/58xo0bx8iRI7Otm2OJxYsXs2PHDkaPHm0yhblIkfF1hUIp2L9f/70kdkKInHhXqULP334jOUvLEeiTPkcsdQL6gf6//vorjz76KI8//jj9+/enc+fOuLq6cvDgQb777jt8fHxYt26dRZMsDNq2bcvGjRt5+eWXeeCBB3BxceHhhx/O90SLt99+m19++YWxY8dy5MgRmjdvztGjR1m8eDHBwcG8/fbbxrLvvPMOP/zwAyNGjODgwYPUr1+f3bt3s3fvXsqXL2/SihgcHMz48eP58MMP6dixI08//bRxuZO4uDhWrFiRa9drTnx9fenWrRvff/89pUqVolWrVly5coWvvvqKmjVrml17zyHynDdrxrBhw5RGo1ELFizIsczChQuVRqNRzz77bL7rT05OVv7+/gpQR44cyXa+SZMmClCHDh3KV703b95UZcqUUV27djVO537kkUfyHZ9SDl7uJORV/VInR8YX/rVLkLNn9cuceHoqlWnGvBCiiLJkWYniKCoqSs2YMUM1bdpUeXt7K09PTxUcHKzGjRunbty4ka284fNx6dKlZuuLj49XI0eOVBUqVFBardZkSY+clkIJDQ1VgJo2bZrJ8du3b6sXX3xRVa1aVbm6uqqqVauql156SUVERGSr49KlS6pv377Kx8dH+fr6ql69eqlLly6pcuXKqcceeyxb+UWLFqlmzZopDw8P5evrq7p06aJ27dqVrRxgNlcxt1xJRESEeu6551TlypWVh4eHatSokVq0aJHZso5a7sSqxK5q1aqqRYsWeZZr0aKFqlq1ar7r37ZtmwJU7dq1zZ6fOXOm2TdIXp5++mnl6empzp8/X7QTu22P6hO7818X/rVLkGXL9Ild+/aOjkQIYQslNbErziIjIxWgXnjhBUeHYjVbJ3ZWjbGLiIigvgUzfOrXr09kZGS+6//nn38AaNGihdnzhuPHjx+3uM7ff/+dn376iUmTJuU4O6jIkK7YQiHj64QQwnkkJiZmO2aYFNK1a9fCDsdpWTXGrly5cpw9ezbPcufOnaNs2bL5rj8sLAyAatWqmT1vOH7lyhWL6ouPj+ell14iODiYd955J9/xOJX0ZIi/rP9eFie2K0nshBDCefTo0YOgoCBatGiBTqfjr7/+YuPGjTzwwAP06dPH0eE5Data7B566CGOHj2abbpvZl9//TWHDx82rjadH4ZNd3NaQ8ew8nNsbKxF9U2ePJkrV67w5ZdfWr0ES3JyMjExMSY3h4i7pF/HztUXPCs6JoYSQBYmFkII5/LEE09w9OhRpkyZwttvv83JkycZN24cmzZtsmoyRHFlVYvd5MmTWbduHWPHjmXFihUMGjSIGjVqAPpWtB9//JG///4bLy8v3n33XVvGm2+HDh3i008/ZdiwYXTu3NnqeubOncuMGTNsF5i1jN2wwWCjtYREdgcPysLEQgjhTMaNG8e4ceMcHYbTsyqxa9CgAb/++iuDBw9mz5492darU0pRsWJFVqxYQYMGDfJdv2Fpk4SEBLPn4+PjAf3U49ykpaXx/PPPU7p0abNr3eTHxIkTefPNN433Y2JiCAwMLFCdVonJ6AKXbli7km5YIYQQRZHVO0888sgjXLp0iZ9//pndu3cTHh4O6PeI69ChAwMGDLB6O5Lq1asDcO3aNbPnDceDgnLfdeHatWscO3aMSpUq8dRTT5mcM6xUffjwYWNLXm7r4nl4eODh4WFB9HYmEycKhSR2QgghiqICbSnm5eXF8OHDGT58uI3C0WvatCmAyQbAmRmON2nSxKL6bt68yc2bN82ei4qKYufOnVZE6SCGXSekxc5uZGFiIYQQRZXVW4rZU/v27fH39+fixYscO3Ys2/lVq1YB+i1GclOjRg2Ufq2+bLft27cD+pZHw7EiQVrs7O7cObh7Fzw9IeN/DCGEEKJIsCixCwsLIywsjPT0dJP7lt7yy93dnZdffhmAsWPHGsfUgX5LsePHj9OpUydatmxpPP75559Tv359Jk6cmO/rFRkp0ZB0S/+9b/63aROWMXTDtmwJVk6iFkIIIRzCoq7YGjVqoNVqOXXqFPXq1TPuC2sJjUZDWlpavgObPHkyW7duZe/evdStW5cOHTpw5coVDhw4QEBAAEuWLDEpHxkZydmzZ7lx40a+r1VkxJ7Xf/WsBG5+jo2lGJPxdUIIIYoqixK7jh07otFojJMhDPftydPTk+3btzN37lx++OEH1q1bR9myZRk+fDizZs3KcfHiYk26YQuFJHZCCCGKKo0qMoPLnEtMTAz+/v5ER0fj51dIrWfHp8O/M6D2KGjzdeFcs4SJjQV/f/0EivBwWcNOiOIkKSmJ0NBQatasiaenp6PDEQKw7H2Zn5zDKSdPiBxkXpxY2MXBg/qkThYmFkIIURRZldg9/PDDfPjhh3mW+/jjj63aUkzkQBYntjvphhVCFBc7duxAo9HkukC/RqPhiSeeKMSorHP58mU0Go3Jzd3dnaCgIJ588kkOHDiQ7TGG+QAPPvig2TqHDx+ORqMhMjLS3uEXKqvWsduxY4dxC7HcnD17tmitEefMlPqvxU4SO7uRxE4IIZxX165dGTZsGKDfw/3cuXMsWrSI9evXs2fPHlq3bp3tMXv27GH9+vX07t27sMN1iAItUJyXpKQkXF3teomSI+kmpMWBRgs+tRwdTbEkCxMLIYT91KhRg86dO7Ns2TKr66hXrx5DhgwxOda+fXt69+7NihUrsiV2QUFBJCQkMGnSJJ544glcXFysvnZRYbcxdjExMezdu5fKMlDJNgw7TnjXBBdZXM0eZGFiIYTQO3ToEH379qV8+fJ4eHgQHBzMnDlzrFq+zN6qVKkC6NfAzcrHx4fJkydz6tSpAiWURYnFzWm1apm2Eq1atSrHvVXT0tK4desWaWlpxoWGRQFJN6zdGbph779fFiYWQlhn69atvPrqq3z66ad06dLF0eEAkJCQkK9xZL/99hv9+vWjTp06jBs3jrJly7Jv3z6mTp3KsWPH+OWXX+wYbe6SkpKMzyUlJYVz584xceJEvLy8GDp0qNnHjBkzhgULFjBt2jQGDRpEqVKlCjPkQmdxYnf58mXj9xqNhri4OOLi4syWdXNzo0qVKvTq1Yu5c+cWOEiBrGFXCGR8nRAlk1KKhIQEm9TzzjvvcPr0ad555x127txZ4DVfvby8ClzHtGnTmDZtmkVlk5KSeO6552jTpg3btm0zDqd64YUXaNq0KW+++SY7duygc+fOBYrJWosXL2bx4sUmx6pVq8aWLVty3D/e3d2d2bNnM3jwYBYuXMiECRMKI1SHsTix0+l0xu+1Wi3Dhw/PtvuDsKMYabGzN0nshCiZEhIS8PHxsWmdR44cwdfXt8D1xMXF4e3tXaA6Ro8ezVNPPWX2XNeuXU3ub9myhVu3bjF37lyioqJMzvXo0YM333yTzZs355nYRUdHk5qaanJMp9ORnJycrfXQy8vLuAFCXnr37m3sCUxNTeXChQssWLCAXr16sWXLFpo3b272cc888wzz5s3jgw8+YPTo0ZQtW9ai6xVFVs1sWLp0KXXq1LF1LCI30mJnVzEx8O+/+u/btnVsLEIIYUt169a1uFv49OnTAIwcOTLHMrdu3cqznt69e5tdFWPlypWsXLnS5Ni0adOYPn26RfFVq1Yt23Pp1asXwcHBvPjii+w3zIDLQqPR8P7779OtWzfmzJnDvHnzLLpeUWRVYvfss8/aOg6RG10axF3Uf+8rixPbgyxMLETJ5eXllePQIktt3bqVPn36ZDu+bt26Ao21s7Qly1YMm1F99NFHNGvWzGwZw2SF3MybN4979+6ZHBsyZAhNmzZl/PjxJsezjuHPr6CgIOrXr8+BAweIj4/PsYWza9eudOnShS+++ILXXnutQNd0ZgVeiyQ2NpaLFy8SGxtLTruTdezYsaCXKdniL4MuFVxKgVdVR0dTLEk3rBAll0ajKVB3p1KKOXPmoNVqsw1bmjNnDr169bL7/uq2UrduXQC8vb0LlJC2bNky2zFPT08qV65sl0klhm7fvLquP/jgA+6//36mTJlSZH4m+WV1Yvfvv//y+uuvs2PHjhwTOoP09HRrLyMg0/i6uvp17ITNSWInhLBWSkoKYWFhJkkd6MeUXb16lZSUFDw8PBwUXf50796dChUq8P777/P0009nG4uWmJhIWlqaTcYP2sqpU6c4d+4cVatWpWLFirmWbdGiBQMHDuT777/PsUWyqLMqsTt//jwPPvggMTExtG/fnhs3bhAaGsrAgQO5dOkSR44cIS0tjV69elG6dGkbh1wCyVIndqXTycLEQgjreXh4EBISQkRERLZzFSpUKDJJHehb6pYvX06fPn0IDg5m5MiR1KlTh6ioKM6cOcOaNWtYu3atw2bFnjt3ju+//x7Qt9JdvHiRr776irS0ND744AOL6pg9ezarV6/myJEj9gzVYaxK7GbPnk1sbCxLly7l2WefZcSIEYSGhrJixQoALly4wHPPPcepU6dyHMgo8kEmTtjVuXNw754sTCyEsF5gYCCBgYGODsMmunfvTkhICO+//z7ff/89ERERlClThtq1a/Pmm2/muKxIYdiyZQtbtmwB9F3opUuXplWrVrz11lvZZvjmpFatWowZM4ZPP/3UnqE6jEbl1Y9qRmBgIP7+/vybMY1wxIgRLF++3KTLNSoqilq1ajFo0CA+//xz20XsJGJiYvD39yc6Oho/Pz/7XuyvLnDrL2i7DGrJxBVbW7oURo6EBx+E3bsdHY0Qwl6SkpIIDQ2lZs2aeHp6OjocIQDL3pf5yTmsGrB1+/ZtGjZsaLzv5uZmDM6gdOnSdO7cmY0bN1pzCZGZdMXalYyvE0IIUVxYldiVLVuW5ORkk/sAV65cyVb29u3bVoYmAEhLgISr+u+lK9Yu1q/Xf7161bFxCCGEEAVlVWJXs2ZNkySuWbNmKKX46aefjMciIyPZsWMH1atXL3iUJVnsBf1X97LgUc6xsRRDkyeD4X+PlSth1izHxiOEEEIUhFWJXbdu3fj333+NyV3Pnj0pX748M2fOZODAgYwbN45WrVoRHR3NgAEDbBpwiSPdsHYzaxbMmWN6bOpUSe6EEEIUXVbNih06dCjJycncunWLoKAgvL29WblyJQMGDODnn382luvatSvvvvuuzYItkYwzYmXHCVuaNUufxJljOD5lSuHFI4QQQtiCVbNicxIfH8/u3bu5d+8e9erVM7vydHFRaLNi9z0Locuh6Ry4b5L9rlPCaLX6LcRyotHo17cTQhQfMitWOCNbz4ot8JZimXl7e/Poo4/askoRI12x9jBjRs4tdobzQgghRFEj+1M5OxljZxdTpsDMmebPzZwp3bBCFGc27KgSosBs/X60qMVuZk6fgBbQaDRMkU9J6yTfgZS7+u996zg2lmJoyhR47z3ItPyiJHVCFGNubm5oNBri4+MpVaqUo8MRAtAPY9NoNMY1gQvKojF2Wq0WjUaTLavUaDTG7w3nsh7TaDQmO1IUF4Uyxi5iH2x5ALwCoU+Yfa5RgsXHg4+P/nuNRt/9KkmdEMXbjRs3iIqKws/PDz8/P1xdXU0+t4QoDEop0tLSiImJISYmhtKlS1O5cuUcy9t8jN3SpUuzHdu3bx+LFi2iWrVqPPnkk9SoUQPQL1K8evVqwsLCGD16NO1kOX/rSTesXRkWJPbzg+hox8YihCgclSpVolSpUty+fZuYmBhHhyNKOBcXFypXroy/v7/N6rQosXv2WdP9SQ8ePMiYMWOYMGECM2fOxNXVtJoPP/yQqVOnMm/ePEaMGGGzYEsc41InktjZgyGxq1bNsXEIIQqPYeN4f39/0tPTSUtLc3RIooRydXXFxcXF5i3GVs2KnTp1KrVr1+a9994ze97FxYU5c+awfv16pk6dyp9//lmgIEssmRFrV9eu6b8GBjo2DiFE4dNoNLi6umZrmBCiqLNqVuyBAwdo2rRpnuWaNm3KwYMHrbmEAFmc2M4MLXaS2AkhhCgurErs0tPTuXTpUp7lLl26VCwnThQKpYPY8/rvpcXOLiSxE0IIUdxYldi1bt2agwcPsnz58hzLLF++nAMHDtC6dWurgyvREq5BeiJo3cA7yNHRFEsyxk4IIURxY9XgghkzZrBr1y5GjBjBsmXLePrppwkK0icfV65c4eeff2bHjh24uroyQ5bwt46hG9anNmhlDIg9yBg7IYQQxY1VGUP79u1Zs2YNI0eOZMeOHezcudPkvFKKcuXKsXjxYtq3b2+TQEscmThhd9IVK4QQorixuinoiSee4NKlS6xatYrdu3cTHh4OQOXKlenQoQNPPfUUPobVX0X+XF0Dx6fpv4/cp78f2M+xMRUzMTH6G0hXrBBCiOLDop0nRHZ223ni6hrY3T/TAQ2goMNqSe5s6ORJaNQISpeGe/ccHY0QQgiRs/zkHFZNnhB2dGIG+mTOQOnvn7B+v16RnYyvE0IIURxZ1BUbFqbfp7Rq1aq4uLgY71uqevXq+Y+spIo5hz6Zy0xBzFlHRFNsyfg6IYQQxZFFiV2NGjXQarWcOnWKevXqUaNGDYu3wNBoNLJlS3741YOoE5gmdxpZpNjGJLETQghRHFmU2HXs2BGNRoOXl5fJfWEHjadljLHLGFtn+Np4mmPjKmYMXbEycUIIIURxYlFit2PHjlzvCxsK7KefKHFipr771S9Yn9QF9nV0ZMWKtNgJIYQojmTlW2cU2E9mwNqZJHZCCCGKI5kVK0ocpWQ7MSGEEMWTRS12u3btKtBFOnbsWKDHC2FL0dEQH6//XhI7IYQQxYlFiV3nzp0LNFkiPT3d6scKYWuG1rpy5SBjPpAQQghRLFiU2A0bNkxmwYpiQ8bXCSGEKK4sSuyWLVtm5zCEKDwyvk4IIURxJZMnRIkj24kJIYQoriSxEyWOdMUKIYQorgq0jl1CQgLbt2/n/PnzxMbGolTWPU71W4pNmTKlIJcRwqYksRNCCFFcWZ3YLVu2jDfeeIOYmBjjMaWUySQLw31J7IQzkTF2QgghiiurumK3bt3Kc889h0ajYdKkSbRr1w6Ar776ivHjx1OnTh2UUrz88sssWbLEpgELURBKyRg7IYQQxZdVid28efPQaDRs376dWbNmUbduXQCef/553n//fU6ePMnrr7/OkiVLaNmypU0DFqIg7t6FxET991WrOjYWIYQQwtasSuxCQkJo27YtTZs2NXve1dWVjz/+mAoVKjBt2rQCBSiELRm6YQMCwNPTsbEIIYQQtmZVYhcXF0f16tWN9z08PACIjY39r2KtljZt2rB79+4ChiiE7cjECSGEEMWZVYldpUqVuHv3rvF+5cqVATh37pxJubt375Jo6PcSwgnI+DqRk61bt9KwYUO2bt3q6FCEEMJqViV29evX5/z588b7DzzwAEopPvzwQ+OSJ3v37mXbtm0EBwfbJlIhbEBa7IQ5SikmTZrE6dOnmTRpktmlm4QQoiiwKrF7/PHHCQ0N5eDBgwA88sgjNGnShFWrVlG1alVatmzJQw89hE6n4/XXX7dlvEIUiCx1IszZvHkzISEhgH4M8ebNmx0ckRBCWMeixE6n05ncHzZsGH/88QcVK1bUV6LV8ttvv9G1a1du377N0aNH8fLyYvbs2QwZMsT2UQthJWmxE1kZWusMtFotU6ZMkVY7IUSRpFEW/PWqXLkygwYNYsiQITRv3jzXsgkJCURHR1OhQgVcXFxsFqiziYmJwd/fn+joaPz8/BwdjrBQnTpw8SLs2gUdOjg6GuEM/vzzTx599NFsxzdt2kT37t0dEJEQQpjKT85hUWKn1WqNO0o0aNCAoUOHMmjQIAJLcLOHJHZFj1JQqhQkJ0NoKNSo4eiIhKMppWjTpg2HDh0yaaHTarW0bNmSAwcOmOymI4QQjpCfnMOirtgDBw4wduxYAgICOHXqFJMmTaJmzZo88sgjLF261GSZEyGcVUSEPqnTaKBKFUdHI5xBSkoKYWFh2bpddTodV69eJSUlxUGRCSGEdSxK7Fq1asWnn37K9evX+e233xg4cCClSpVi+/btjBo1ikqVKvHMM8/w+++/k56ebu+YhbCKYamTihXB3d2xsQjn4OHhQUhIiHG8MEC5cuU4fPgwISEhxjU6hRCiqMjXrFgXFxcee+wxVqxYwa1bt/j222/p0qULKSkp/PTTT/Ts2ZMqVarw2muvGWeYCeEsZOKEMMfFxYVbt24Zu1zv3LlDrVq1qCZTp4UQRZBVy50AeHl5MXToUP7880+uX7/O/Pnzad68OREREXz22We0bduW+vXrM2fOHFvGK4TVZKkTYc6BAwcAaNy4sXGx9bNnzzoyJCGEsJrViV1mFSpU4PXXX+fQoUOcPn2ayZMnU65cOc6dO8fUqVNtcQkhCkxa7IQ5hsSuTZs21K9fH4AzZ844MiQhhLCaTRI7g8jISDZv3szmzZu5c+eOLasWosBkOzFhjiR2QojipMCJXWJiIj/++COPP/44VatW5fXXX+fgwYOUK1eOl19+mf379xeo7qlTp1KvXj08PT2pUqUKI0eO5Pr16xbXERUVxQ8//MAzzzxDzZo1cXd3x9fXlzZt2rBw4UJSU1Otjk8ULdJiJ7JKT083jgc2DB8BSeyEEEWXqzUPUkqxZcsWvv/+e9atW0d8fDxKKTw9Penbty9Dhgzh0UcfxdXVquoBSEpK4uGHH2b//v1UrlyZ3r17c/nyZZYuXcrGjRvZv38/tWrVyrOejz/+mDlz5qDRaGjWrBlt2rQhIiKCPXv2cPDgQVatWsWff/6Jl5eX1bGKokHG2ImsTp48SXx8PL6+vtSvX9/4T6MkdkKIoipfLXaHDx/mjTfeoGrVqjz22GN8//33xMfH07FjR7755htu3rzJypUreeKJJwqU1AHMnj2b/fv3065dO86dO8dPP/3EgQMHmDdvHhEREYwcOdKiery9vXn77be5fPkyR44cYeXKlfz111+cOHGC6tWr8/fffzN79uwCxSqcn04HhoZeabETBoZu2FatWuHi4mJssbtw4YK05gtRxGzdupWGDRuydetWR4fiWMoCs2fPVg0aNFBarVZpNBql0WhUw4YN1dy5c1VYWJglVeRLcnKy8vf3V4A6cuRItvNNmjRRgDp06FCBrvPDDz8oQNWoUSPfj42OjlaAio6OLlAMonDcuKEUKKXVKpWa6uhohLN47rnnFKAmTpyolFIqPT1deXl5KUCdOXPGwdEJISyl0+lUq1atFKBatWqldDqdo0OyqfzkHBa12E2ZMoUzZ86YzH49efIkEyZMsMu2Ynv27CE6OpratWub3Zv2ySefBGDDhg0Fuk7Tpk0BCA8PL1A9wvkZumErV4YCNiaLYsQwBrht27aAfiux4OBgQLpjhShKNm/ebBwvGxISwubNmx0ckeNYlNgZdpUwrFfXokULuwb1zz//AOR4HcPx48ePF+g6ly5dAqBSpUoFqkc4PxlfJ7KKiYnh1KlTgH5GrIFMoBCiaFFKMXnyZON9rVbLlClTsm0VWFJY1HaxYsUKe8dhIiwsDCDHld8Nx69cuVKg6yxcuBCA3r17F6ge4fxkRqzI6tChQyilCAoKMtlSTBI7IYqWzZs3c+jQIeN9nU5nbLXr3r27AyNzDJuuY2crcXFxADnOVPX29gYgNjbW6mt8+eWXbN26ldKlSzNhwoQ8yycnJxMTE2NyE0WHrGEnsjJ0w2ZurQNJ7IQoSpRSTJkyxbgloEFJbrVzysTO3nbv3s1rr72GRqNhyZIlVKlSJc/HzJ07F39/f+PNHmMLhf1IV6zIyjAj1jC+ziBzYlcSPxSEKEpSUlIICwvL9ruq0+m4evUqKSkpDorMcZwysfPx8QEgISHB7Pn4+HgAfH198133v//+S+/evUlJSWHhwoX07dvXosdNnDiR6Oho4+2qIVMQRYJ0xYrMlFImO05kVrduXTQaDVFRUdy+fdsR4QkhLOTh4cGWLVuMLXbu7u4AfP/994SEhODh4eHI8BzCKRO76tWrA3DN0H+WheF4UFBQvuoNDQ2lW7du3Lt3j+nTp/PKK69Y/FgPDw/8/PxMbqLokMROZBYWFsatW7dwdXXNNvO+VKlS1KhRA5DuWCGKghMnTqCUonHjxjz00EMAREdH5zhOv7hzysTOsAzJkSNHzJ43HG/SpInFdd64cYOuXbty48YNXnvtNaZNm1bwQEWRkJ4OhhVtJLET8N/4umbNmlGqVKls52WcnRBFh2HpsyeeeMLYAl+Q7UyLOqdM7Nq3b4+/vz8XL17k2LFj2c6vWrUKgJ49e1pU37179+jevTsXL15kxIgRfPLJJ7YMVzi5mzf1yZ2LC8jKNgLIsRvWQBI7IYqG1NRUNm3aBJgmdobf8ZLIKRM7d3d3Xn75ZQDGjh1rHFMHMH/+fI4fP06nTp1o2bKl8fjnn39O/fr1mThxokldCQkJPP7445w4cYIBAwbw9ddfZ5s9I4o3QzdslSr65E4ISeyEKB727t1LVFQU5cqVo02bNsbf6XPnznH37l0HR+cYTrsG/+TJk9m6dSt79+6lbt26dOjQgStXrnDgwAECAgJYsmSJSfnIyEjOnj3LjRs3TI6/++677Nu3DxcXF1xdXXnuuefMXm/ZsmX2eirCwWR8ncgsJSWFw4cPA5LYCVHUbdy4EYAePXrg4uJCuXLlqFOnDhcuXODgwYM8+uijDo6w8DltYufp6cn27duZO3cuP/zwA+vWraNs2bIMHz6cWbNmWTwo8t69ewCkp6fzww8/5FhOErviS9awE5kdP36c5ORkypQpQ926dc2WMSR2V65cISEhIcc1NYUQjmVI7DIPzWrbti0XLlzgwIEDJTKxc8quWINSpUoxc+ZMLly4QHJyMjdu3GDp0qVmk7rp06ejlMqWoC1btgylVJ43UXzJGnbW2bp1Kw0bNmTr1q2ODsWmMnfD5jQsIyAggDJlyqCU4vz584UZnhDCQhcuXODMmTO4urrSrVs34/GSPoHCqRM7IWxBumLzTynFpEmTOH36NJMmTbLJPz/OkijmNb4OQKPRSHesEE7O0FrXsWNH/P39jccNv9sHDx4skQ03ktiJYk+6YvPvl19+ISQkBMC452JB2CNRtJbhv/isO05kJYmdEM7NkNg98cQTJsebNm2Kh4cHd+/e5cKFC44IzaEksRPFnnTF5o9SirFjxxrvazSaAu+5+Oeff9o0UbTW3bt3jV2rrVu3zrWsJHZCOK+YmBh27twJZE/s3N3dadGiBVAyu2MlsRPFWloaGCZKS4udZRYuXEhkZKTxvlKqQMmYUorRo0cb77u4uDhsc+6DBw8C+m3DypYtm2tZSeyEcF6bN28mLS2N4OBgs5OgSvJ6dpLYiWItPBx0OnBzg4oVC+eazjKWzBppaWlMmjTJ7Ll3333XqmRswYIFJnsrp6enO6zVzvDfe27j6wwMid3Zs2fR6XR2jUsIkT+Zd5swxzDUQhI7IYoZw/i6qlVBWwjvdp1Ox6uvvuoUY8ms8cUXX5CYmGj23JkzZ0hJSclXfbdv3+add97Jdlyr1Tqk1c7wRz6v8XUANWvWxM3NjcTERJPEtLgoyv+AWKskPufiKD09nd9//x3IObEz/PN27NixHP+mFVeS2IlirTDH1yml6NmzJ6dPnwYcO5bMGrdv32b69OkAvPPOOxw+fJjDhw/z0UcfARAfH28cJ2eJ9PR0Bg0aRGpqarZzOp2Oq1ev5jtRLAillEUzYg3c3NyoU6cOUPy6Y5VSTJgwocj+A2INZ5rAIwrm4MGDREZG4u/vT/v27c2WCQoKomLFiqSlpXH06NFCjtCxJLETxVphLXWilOKtt94y/hcJtpl0UJgmTJhAVFQUzZs3Z86cObRo0YIWLVrw1ltvMXz4cACGDh1KTEyMRfXNnj2bv/76C09PT37++WcOHz5snLAwduxYQkJC8PDwsNfTyeb8+fPcu3cPDw8PmjRpYtFjiuM4u8TERF5++WXj7htF7R8Qa/34449OMYFHFJxhNuxjjz2Gm5ub2TIajabErmcniZ0o1gorsZs1axbz5883OVbQSQeFae/evSxduhTQd8e6ZNlUd+HChQQFBXH58mXeeOONPOvbvHkzM2bMAGDRokU89dRTtGjRgueffx6A3bt3W7x7jK0YWutatGiBu7u7RY8pToldbGwsH374ITVq1OB///ufybk33nijyPwDYg2lFG+++abxviMn8IiCy2t8nUFJnUAhiZ0o1gpjDbtPPvmEadOmAZjdyWDy5MlO/QGSlpZmXN7kueeeo127dtnK+Pn5sXz5cjQaDUuWLGH9+vU51nft2jUGDx5snA07dOhQ47l+/frh6urK8ePHCz1Zys/4OoPikNjduXOHadOmUb16dd555x1u376drczp06dZt25d4QeXB1uNifv111+5deuW8b4jJ/CIgrly5QonTpxAq9XmuV1YiZ1AoYRVoqOjFaCio6MdHYrIRatWSoFSa9fap/6vv/5aAQpQ3t7exu8z3/z9/VVSUpJ9ArCBzz77TAGqTJky6vbt27mWHT9+vAJUQECAunnzZrbzKSkp6oEHHlCAat68uUpMTMxWpkePHgpQ06dPt9lzsMT999+vALVy5UqLH3PgwAEFqEqVKtkxMtvasmWLatCggVq5cqUaN26cyfsyODhY1axZU2m12mzv03LlyimdTufo8I10Op1q1aqVAlSrVq2sjk2n06kaNWpke74ajaZA9ZZEhvfWli1bHBbDF198oQD14IMP5lk2OjpaaTQaBagbN24UQnT2k5+cQxI7K0liVzRUqqRP7A4dsn3dP/74o/GPxvjx49WVK1fU4cOHjbeXXnpJAap06dJmkyBncPPmTeXv768A9X//9395lk9KSlKNGzdWgOrZs2e2D8U333zTmMxevHjRbB3Lly9XgKpfv36hfagmJCQoV1dXBajQ0FCLHxcVFWVMBO7du2e3+GxFp9Op5s2bGxMXQ+zNmzdXq1atUvHx8apixYpm/wEB1Hfffefop2D0+eefm8S2adMmq+pJSkoy/uyz3ipVquTU/3Q5E1sl2gX12GOPKUC9//77FpW/7777FKDWrVtn58jsSxK7QiCJnfNLTlZKo9Endrdu2bbuX3/91fhhMWbMGLN/5FJSUlSzZs0UoJ566inbBmAjw4YNU4Bq2bKlSktLs+gx//zzj3J3d1eA+vrrr43HV69ebfzAzO2PaHR0tPLw8FCA+ueffwr8HCyxZ88eBaiKFSvm+wOpcuXKClD79++3U3S2s2nTJpPE5b777lN//PGHyXMOCwsz+Qfk8OHD6rnnnjMm5FeuXHHgM9DT6XQmCaiLi4vVycTBgwcVoNzc3NTWrVvVpk2blKenpwLU559/bofoi6c//vjDJol2QcTFxRn/dpw8edKixxje2xMnTrRzdPYliV0hkMTO+YWG6pM6d3elbPnP5datW41/XIYMGaLS09NzLHvkyBHl4uKiALVmzRrbBWEDu3btMrbsHDhwIF+P/fDDD43dzxcuXFDnz59Xfn5+ClBvvfVWno/v06dPof6xnT9/vgJUr1698v3Yhx56SAFq2bJldojMdnQ6nbG7GVBardbiZCglJUW1adNGAapDhw4WJ/n2kjVBLUgyMXz4cAWooUOHGo/NnDlTAap69eoqISHBlqEXSzqdTtWrV8+q95YtrVu3TgGqZs2aFl970aJFClAPPfSQnaOzL0nsCkFxTeycYQyFrezapU/satWyTX1btmxRNWrUMP6337dvX5Wamprn4yZOnGjs9rl7965tgskhPkt/dqmpqcYu1dGjR+f7Wmlpaapjx44KUA0bNjQmug8++KBKSUnJ8/ErV65UgKpVq1ahfDgMGDBAAWrOnDn5fuyLL76oADVhwgQ7RGY7BU2GLly4oHx8fBSgZs+ebedoc6bT6VTLli2zPQ9rkok7d+4Yf1/37t1rPB4fH6+qVatm9XuipMnaWueoVrtRo0YpQL3yyisWP+b48eMKUD4+Pg7/h6UgJLErBMUxsXOWMRS2smKFPrHr1Kngdel0OuNYDUB17drV4rE5iYmJqn79+gpQI0aMKHgwZiQnJ6tatWopQDVp0iTXVkSllFqwYIECVNmyZVVkZKRV1wwNDTUmAoBydXVV165ds+ixcXFxysvLSwEqJCTEquvnR1BQkALU1q1b8/3YhQsXKkD16dPHDpHZhuF3N/O4OmuSoW+//dbY9emoruekpCRVtmxZm4yJmzdvngJUs2bNsr0G33//vfEDPzw83NZPo9jQ6XSqbt26Nkm0CyI9Pd04LOLPP/+0+HFpaWnGv1PHjx+3Y4T2JYldISiOid1PP/3k8DEUtvT++/rEbsiQgtf1f//3fyavTX4H4v7999/GD938/FGyxLlz50y6SUA/YaNXr17qvffeU3/99ZeKiYkxll+5cqVxVuSiRYsKdG3DZAlr3jNPP/20AtS4ceOsuralLZQ3b940djlb8/v6559/KtBP9rBHfLaQlJSU46SI/CRDOp1ODRw40Niamvl9U5hmz56tANWuXTs1bdo0BfpZ2+fOnbO4jvT0dGNC8tVXX5k937p1awWokSNH2jL8YiUxMdEpJp8cOnTImIjn95qdO3dWYDomuKiRxK4QFLfEbuPGjdl+eVu0aOF0rXb5+bDs3XuLggZq4MCCfbD++eefJstDWDuQ+5VXXlGACgoKUrGxsQWKSSn9h/A333xjbPnK7abRaFSjRo3Uc889p3x9fRXox8cVpGvCMKbLkLDm93VZs2aNAlRgYGCeLYzmrm1p6/L69esV6CcSWOPKlSvGFklLupnzG5+tnDt3ztgl/ssvvxgnRly9ejVf9dy7d8/Ywvnss8/aJ9g8PPvsswpQU6dOVSkpKcblSj755BOL69i8ebMClJ+fX46/b3v37jX+fhw5csRG0Rcvv/76qwKUp6en2rp1q+rXr59xKEp+31sFMX36dAWofv365fuxEyZMUIAaNWqUHSIrHJLYFYLiktjFxsaq0aNH55gQOFOrnU6nUy1atDC2nhw8eFCdOHFCXbhwQV27dk3duXNHxcfHq/T0dKXT6VTp0voP1urVrf9gXbx4sdk1v6x5bWJjY40fUC+//LJV8RhERkaqvn375prMjR49Wg0YMMD4IW3rn29Bx3QlJiYak8y///67QNceM2aMWrdunTp27Fi2ZUkMLVDdu3fP1zUM0tPTjcnzmTNnrIqvMH6Ptm3bpgBVuXLlAieSu3btMr7v87Pun60Yhi5s3LhRKfXfAPjKlSubXRvRHMPvR16/a4b3R+fOnZ3uH1lHy7x8jmGM6ZYtWxSgypcvb9EYY1sxjLtcsmRJvh+7du1aBahGjRrZIbLCIYldISgOid2ePXtU7dq1c00OCmtwe26Sk5PVr7/+amxOt+SWtfUxvx+sOp1OvfvuuznWb+34EkMrgqH1wZquus2bNxvHmri6uqpq1aplSz6zxnfjxg21du1aValSpQK3PCr1X4tUXtfNy9ChQxXkbzC0TqdTNWvWzPXn7+/vr5o0aaJ69uxpXJolKCjI6vey4cPNki54nU5nXOamIO+V/Jo0aZIC/UxtW5g8ebKxZbdOnTqFNqHq3r17xtfOsGB2cnKyCgwMVGDZEiVXr141vjfzWhbj8uXLxgkWa+21knkRZUiIfHx8jGNxU1NTVbly5RRYN2bVGj/++KPxPWHNmqDh4eHGlllHDS8oKEnsCkFRTuySk5PVxIkTjX/4qlWrpsqUKWP2A1Kj0ajTp09bfS1Lu06zlktLS1N//fWXGjVqVI6xubm5qXLlyikfH58cx4BkTlAt7e5LSkpSgwYNMj42px0lrB1fMnLkSAUYu80s/dBPTExUb7zxhvH6wcHBat++fRaPrbLlEhK2GtO1ceNG42Ms7Rb+6quvzF63Tp06qnz58rm+D6xtOXvmmWcUWLYoqi1f5/wwLFdiq2VZUlJSjGPQAHX//fcXyj95hn9+amWZzm7YcSAwMFAlJyfnWsfUqVMVoDpZOHPKkBTXrl1bFizOkJ6erpo0aaIA9e6775qcM8xOfeGFF+weR+adQ7y9va1+D1avXl0Batu2bTaOsHBIYlcIilpiZ0icFi1aZNKaMHToUHXv3r1si5YeOHDAuBxG27ZtLR5blJml44wyl2vQoIF69dVXjS1ShltOyV3mD8vU1FQVGxubbRKI4da4ceM8F8S9c+eO6tChgwJ9a9iSJUvMLuhqzdglg3v37mWb9Td48GD1ww8/qCNHjqi4uDiT8lu2bFG1atUyaaV68cUXVXx8vFLK/IKzWeOzVQtbZrZ4XZKTk40/W0v+4MbFxRlbV3J6HnFxcerkyZPqt99+U0FBQVaPAczMsO7Z8OHDcy2n0+mMH4a2ep0tce/ePePP1pbjnpYsWVKoyalSSs2aNUsB6plnnjE5npiYaPy7kNukn5SUFGPL9E8//WTRNWNiYoyP+fjjjwsUf3GxatUqBfoxinfu3DE5Z5hQFBAQYPfuWFsNa3jqqacUoN577z0bR1g48pNzuCKcSnx4OMlRUXz9NXz1FbzwAjz/PHiULo13lSpWlUu6d4/hQ17n+q3TjB49GoCyZcqw6Ouv6d+/PwBuCQl4e3qa1Ld83jw6P/kk+/fvZ/r06cyZMydf1/1j40ZCQkIACAkJoW3LlgQEBICbG+np6aSnp5OSkEBERASnzp0D9JuRnz59GoAyZcrQv39/Bg4cyPg33yQqKgqllPEaGo2GSe+8Q7du3dBoNLi6uuLt7c0H772HRqMxKQtw4sQJmjVrxtixY5kxYwYeSUkkR0UZz1++epWnX3yRC6Gh+Pn5sWbNGh555BHiw8Px9vTM9rPy0GrN/uyylcvy2rjGx1Pa15e7d+8aj61YsYIVK1YY71evXp26NWtSs2pVft28mduRkQCUK1OGLz/5hCeffdZYtqyLS57xpaSkcCU0FJ1OZ1JGp9MRdvkyKSkpeHh45Ot5WHJdS+rr168fixcv5vslS2hasWKu13355ZdJSkrKVibz8/D29qZhw4acP3aMK1euGMsYNn7/9ccf6T1okMXxAdSvXx+Af48e5e6pUzmWS0lJ4dzZs7nGl9/X2ZJyO3bsQKfTUadmTbxiYkxitKY+gLjr1/ls/nyT36WJb71F+0aN8Kla1eSxtnwuBw8eBKBR9erZXuvXX3iBd6ZP57333mP48OGkRERkq2/9n39y8+ZNKlasSJ8+fSy6rq+vL7Nnz2bUqFHMnDGDnm3aUL5s2QI9j6Jczs3Pj+nTpwPw+uuv45GUZPKzaFqxImX8/YmIiGDXrl08/PDDdokv7vp1Xsz4zALQarVm34OW1NemTRt++eUXdm/dygu9e9skPkvLFTaNyvrpJywSExODv78/0dHR+Pn52aTO+PBwNjz+OLqUlGzntO7u9PztN7yrVMlXuSVdurAqPJxd0dHGMrU8PXmrdm2Gbd6cZ30HExJYePkyGo2GDStXEjt3rkXXXfvYY7xy8iRR6en5fh28tVrGVK/Ou9u3U6ZGDe6GhlKrXj2i09KylfV3deXSuXOUrVkTINeybhoNqRlv97JlytDP25tOvr6cio/n6xs3SEhPJ0Gno7ybG79t2kTrhx+2y89kdocOvH/pUrZy1Tw8SPDy4u69ezm+Ni9XrUr7gACrrrusa1eiEhOzlStdqhTDt2zJd322Krf35Em6deuGj4sLX9Srh6tGY7bcuu3bGTJkCAAjK1WiVqlSOT6PuOvXaVq3LqGJiWT+A6cBapYqxT/nz+NTtarFz+PAX3/RtksXvLRaFgUHo8kUY+Zyh3bsoNVDDwHwQuXK/BIRwd20NIZVqkTrsmXt9jqPGTmSr5YupUuZMoyoXLnA9eX2Pp1QqxaTd+82fnDZ8rl4Va5MxQoViIiMZHqNGtT18jIpl+rqyvjwcCIiI/ly/nz8ly/PVt+cy5c5lZDA26+9xgcLFlgcX8zVqzQJDuZKYiLNfXy4lZLCs5Uq0cjHx27vfWctdyA+nk+vXMHf35+T+/axe9CgbOW+Dg9nR1QUzw0dyjfLl9slvokPPMBnmf45M8j8HrS0vq3r19O1Tx/8M/7O5PQ7bOvnYSv5yTmkxc6JJEdFmX2TAOhSUki4eROP0qVJuHkz13Lh586xdc0ali9Zwv6M1i8DDfr2bD+dzqL6Wnt5MbRvX75bu5bnxo5lRtmy+Lpmf9tkju/CP/8w8exZs0ld97Jleezll/GtWpWk27fZtGABG+7cMSkTr9PhqtORdvcuaRUqkH7vHrNq1iTGTLLm5+pK+r17pGW09ORVtsqbbzL10085dfo039y7x1YPD2LS07mbUT7Iw4Px1atTs3Rp0hIS8nytLf2ZGMrF37jBz+Hhxp+DgQZw12g4vGULuoAADm3dyvp33+WXiAiiM15HLfD7nTu09fPL93UTbt6kDFAmSzJkYE19tirXoU0bypcpQ+S9e5yKj6eJj0+2csf37+eFF14AoF/58jySqTXF3POIunqVOykpZP2vVQF3UlKIunoVzzJlLH4eVby80AAJOh0x6en4Z/odyFxu2syZANzv60vHMmU4lZDA7uhoYtLSKIP9Xudt27cD0Mjb2yb15fQ+Bfg5PJw3btzAo3RpyHhOtnouN6KjiYiMxAUIMtMa7JaWxouDBzNz4UI+XLCA6d7euGT6gL6enMyphAQ0wDPduuXrdzg5IoLBFSrw3pUrHI2LA+Cn27e5z9vbbu99ZyynU4pVN24A8Porr+CemGi2XBs/P3ZERbH+t9/4IjbW5vHFhYez+OrVbGU0mL4HLa2vXkAALkB0ejqRqakEuLsXKL68yiVHRTms1U5a7Kxkjxa7D944ReDmp/L1mH/j4vj25k0GV6xIqlL8HR3Nsbg40vL4sb5TvXq2D9CcJOt0TL50ifCUFJr7+DAuMNDkv53MjsXG8r/r14nP0uUHGa0lnp7MrFnT2L0zNTSU0KSk7K0qmcrZWppSbL17l1URESRmifONatW430Y/T3NSdTpeO3/emKxl5u/iwsK6dXHL6Mo8HhfHB2Fh2crl52dXVCy9cYOt9+7RqXRpRmf5Y5ii0zEtNJSw5GQaenkxMSgIrQXvizupqTkm+OXc3PId4xvnz3M7NZXJQUE0MJNAXUxMZGpoKBrg/dq1qebhwfZ79/jmxg0aeHkxuUaNfF/TEndTU3nl/Hk0wFfBwXi7uBS4zvy8T21pX3Q0n1+/Ti1PT2bVqmW2TFJGbHHp6bxUtSrt/f2N55bfvMmfd+/S0teXNwMDrYphemgo5zO1bBfH37fc7ImO5n/Xr+Ot1bKgbl28cng/pSnFS2fPEq/T8W5QEA3N/E4UxF9377Lk5k2z56x9D06+dInQpCReqVqVtpneN/bw6C+/ULZhQ5vVJy12RdRXX8HsmpaXV0qx/OZNwlNS+PjqVZPkqLqHBw/4+bE3JoarycnZEqdfbt+msbe3RYmTh1bLy9WqMS00lKNxcfx59y6PlitnUiZNKX6+fZvfMlrftEDW1E6h/7BNUwo3jYY0pbiTmmq+VSVTOVtz1Wh4tFw52vr5MeHSJWIztYitj4ykpa+vXRJKADetllm1auWYcBj+UCml+OX2bbMte/n52RUVbf382HrvHiExMYyoVMnkD/b3t24RlpyMn4sLL1WtalFSB1DOzc2qBC4nVTw8uJ2aSnhKitnE7qdbtwDo4O9PtYxxdPUyuhIvJiaSplS2bmZbOBkfD+j/GbJFUgfZ36dHYmNZExlJNQ8P3q5e3S5JHehfJ4DaObQsA3hqtfQoW5afIyJYFxFBOz8/tBoNSToduzLGO3UpU8aq6yulTP7ZK66/bzlJV4q1EREA9ChXLsekDvR/R+/382NnVBQHYmJsmtjdTknhh9u3AehepgwdMlqHDTL/rcyP2qVKEZqUxIXERLsndo5kn99OYZWMnqYc/dPsO+ovDuGfZt+RphT/u36d6xlNwQrw0Wp5olw5hj+2krU77lLl4V+JTkvLMXE60mSJsb68rtt9xQk6tRgPwI+3b3M50wD2iJQUZl2+bEzqWtR7mo9q12Z2zZrZbrNq1eJUixXUXxzCqRYrmFWrVp7lLImv/uIQi8pee+Q7BoSE0PW77whLTjYmdaBPRC8lJXEiPp6u3/1XLjfWlCvn5kbNUqWy3cq5uRnLdVqyJNekt9OSJXaLzxHlXl61ijKuriTodJzISFQA9kdH89e9e2g0GlauWcOAlSsd9jwqZ3TdhCcnZyvn/vLLnExIwN3NjX4BAcbjVdzd8XFxIUUpriQl2SW+2E6dAPPdsNbUZ+592jkjUbqenIynVmssZ+vnEh0cDOSe2HX97jv+7/hx/H19CU9JISQ2FtC39iXqdFR0c6ORt7dVz/lEfDzXMv18FYXzN8Hg37g4xl+4wL8ZXcEFrS+/5fZGR3MjJQUfFxc+WL06z/pa+/oCcMLNjYeXLbNJfA8vW8YvAQEk6XTU9/JiSKVKuf6tzM/zrZPxvrpgZqyxrV9nR5IWOyfy/POwaXPO599515OyDb2IvR7K0FUXuZqpf18DBLi7M7BCBR77uDFlG3pRY6ofNY7k3Do0eKqfvpyfJ5ty6QE2XHflt8Po1vZ/HImLY15YGB5aLe38/fnzzh3idTr8/fxYumwZnYKD2fRUzhUOzqhPf92cW1VMy+UdH5Bn2VFjPHH18kLr4ZFri9h4Dw9cvbxwMTPOJzMXT0+7lPPy88u1Zc/Lz8+h8dm6nJuXF238/Nh09y77Y2Jo4evLzZQUvjaM9Xn+eR7r1SvbLMnCfB5VMlrhsiZ2SinmfPEFAMOffpqAI0eM5zQaDfVKleJIXBxnExJsHp/Ww4PtO3cC0CiX7sKCXrecmxuV3d25kZLCqfh4+meUMzzGFs9F5+LCkaNHgdwTOxdPT8pWqsSYYcP44IsvWBsRQStfX7ZmTDp6pEwZtBpNvp+zo/8mKKX46fZtwlNSjGP7NFY8D2vLpSvF2ozZ94+XK4d/uXJ51tfIxwd/Pz9u3b5NiI1+N//3ww/s3bcPH29vxlSunGMLvTXP15DYXU5KytaCbuvX2ZGkxc6JeJQujTbTgM7MtO7uaLy8mDZtGl0GDjRJ6kD/hyg0KYl/k5ONg5o9SpcmwNvbbOtQgLe3Sbncrmso51mmDGNq1KC0iwt309K4kZLCmogI4nU6ant5sXfzZvr27WtxfbYul5+yGi8v7uTUmpmWhibjQ8tRz8XWP7uiUO6BjO79w7GxxKen89m1a/r/2r29mfbuuw6Pr1pGi9iNLL97hxITOXbyJN7e3kwYPz5bfYbu2PNJSTaP73JkJOHh4Xh6ehKcQ9eSrV4XQ4vgyUzPw5bP5cLNmyQlJVHa358qOSSpmet7+aWXKKXVcjU5mZ8zehHcNBo6Zlwnv8/Z0X8TjsXFcSmjJ8TQSliYv5t/R0dzKyUFXxcXHq1Y0aL63D086PnoowD8tnNngeMLS0vj/Yx/kj6eNYuKFrwP8vN8q/j44K3VkqoUYZl6nez9uVTYZPKElewxeQJyXp/uzLVrvDh+PMePHwegtL8/0TEx2dZ1a96kCYeOHjWOB7HHungfzZvHjPnzjcd6du3Kt4sWUSbT4HB7XNeScvkpezYkhHAzU+mr1qhBvfvvz1ZfVo5aY6q4lou7fp2GrVtzNTwcD3d3klNSKFu6NPu2bHGKn8flEyeo2aQJGo2GsJAQvEqVIi0tjQ79+3PuwgWmTJnCzJkzs9V38OhRHhsyhIDy5bl1+3a2382CxLdk9WpeffVVunTpwrpvv7Xr6/L7tm0MfeUV6taqxbmLF00ea4vnsnz9el566SW6devGmqVLLarv7dde46NPPzXe79SuHWu++cbq55z5b8L4WbM4fPw4IwYMYML48XZ9D8Zdv06z9u25mHFtjUZDs/vuY9emTfler82acn/t3s3gl18mNS2N6ePG8dabb1pc385jx3j88cepXLkyZw8eJDUmxqr4kpKT6fLMM5w+e5a+ffuyevVqEm7csPnz7TVgANv27OGDd99lVMZ6lvb+22EL+co57LBAcolg750nDDtF/P7772rq1KnGLbPKly+vvv/+e5ts52QNww4GhtX8C2sfTFEyjB8/3uT9bNgE3hnodDrjjiHHjh1TSv23M0O5cuVUVFSU2cclJSUZt487f/68TWPq3bu3wsKtzgoqKirKuLvFlStXbF7/s88+qwA1efJkix8TERGhvLy8jO+XBg0a2Oxv0bJlyxSg6tWrZ/e/b47ahk4p0y27XF1dVWxsbL4en5ycrPz9/RWgdu3aZXUcb775pgJUxYoVjXsE28O0adMU2G5P5cIiW4oVAnsmdpm32CpVqpTxl7x///7q1q1bSinbbOdkDUf+ARLF32effebU76sHHnhAAWrlypUqMTHRuDF9XttQPfjggwpQS5cutVksqampys/PTwEqJCTEZvXmpm3btgpQixcvtnndDRo0UIDasGFDvh5n2CrK1u+Z6Oho4/Z19nx9dTqduv/++83+XS2M/Xl/+OGHAr9+w4YNU4B65ZVXrIph27Ztxuvn9+efX7///rsC/V7jee1h7kwksSsE9kzsNmzYYPKL5ufnZ/Geh/Zkj/1GhTAwfMDZYm9Xexk5cqQC1PTp09Unn3yiAFW1alWVkJCQ6+PeeecdBajnnnvOZrHs27dPgX4f5bS0NJvVm5spU6YozOzjWlBRUVHGn3t+Wmt0Op1q0aKF3d4zTz/9tALU66+/bpP6zElKSlLlypUzm9j5+vratQcmPDzc2JpckNfP8JlVpUoVlZ6enq/HRkVFGf9BGj16dL4ea42IiAjj823evLlT/X3JTX5yDpk84WSUUkyZMsV4X6PRUKtWLZ7KZZZpYUlJSSEsLMzsfqNXr14lJYdVuIWwxObNmzl06JBx3Khhb9fNm3OZKl7IDHvGhoSEMGfOHACmT59OqVxmcQI8+OCDAOzZs8dmsfz1118APPTQQ7jYaP26vHTp0gWArVu3Zvs7UBAhISEopahZs6Z+P2kLbd68mSNHjtjtPTN48GAAVq5cSboV2yNawsPDgxdffBGAtm3bcvjwYd7NmCyUlJTEuYx9tG3t1q1btGnThuRMs7ytff26du2Kn58f4eHh7Nu3z+LHbd26laCgIK5evUrt2rWZN29evq5rjcOHDxu/P3r0qFP9fbEZOyeZxZa9WuycvavTUV3AongrKq3Bv/76q0l89erVU6mpqXk+7s6dO8bHRERE2CSWzp07K0D973//s0l9lkhOTlbe3t4m4wxtYfbs2QpQAwcOtPgxhfGeSU5ONo6r3Lx5c4Hry8nDDz+sALVgwQKllP65PfHEEwpQjRs3tnmr3a1bt4xd31lv1r5+Q4cOVYB67bXXLCqv0+lU7dq1jdfds2ePFc8kf7KOEcfKVkZHkK7YQmCPxK6ofLgJYWtJSUkOmxCUH2fPnjWJLT9DJBo2bKgAtX79+gLHER8fr9zd3RWgzp07V+D68qNHjx4WjSvMj549eypAzZ8/3+LHFNZ7ZsyYMQpQw4YNs0l9WUVHRxsnx2WeXHPz5k0VEBCgAPXWW2/Z7Hq3b99WjRo1Mn622Or1M/zTU7Vq1TwTpZSUFDVo0KBCb7zIqeGkd+/eTp/cSVdsESVdnaKk8vDwICQkhMOHD2e7hYSE4JGxOLCjXbhwweS+b8bK+5YwdMf+/fffBY7j77//JiUlhcDAQOrUqVPg+vLD0B27ZcsWm9SnlOLgwYMAtGnTxuLHFdZ7xtAdu2bNGhISEmxSZ2Zbt24lLS2NunXrmvwsK1asyDfffAPAvHnz2LFjR4GvFRkZSZcuXfj333+pXLky27dvt9nr17VrV3x9fbl+/Tr79+/Psdy///5L69b/396dx0VZ7X8A/wyD7DtCLmwXVFQQEkwl4KLhAm6YKVfTQs26paZdLe8tM69276vSUKvr1bRceomm4ZKaEmJeckEFERFEQRREMEVkVRyW+f7+4DdPTjMsMzAL4/f9es3L15znOYczHOd5vpznLIOxc+dOIU0sFmPZsmVyy3d1NPr/YU5GSrYi+/HHHzFr1iw0KFkQvlPSdJRpqDT1KJYfdTKmn56crQ41etK3b99OACgoKKjddZEtCzNr1qx2l6WqzMxMAppm7HdEr1hBQQEBTUtttDYJRRcaGxuF5UC+//77Di9fNiGnuQkac+bMIQDk5ubW7JI6bXH//n3y9/cXeuSuXr2qdlnNmT59erOfpaGhgVatWiX0NCt7abLXrqUeXtlr4sSJevN04I/4UawWaHodO8aYfmnv+Nf8/HwCmpZZaG8AExAQQAAoLi6uXeWoQyqVCjfIEydOtLu83bt3EwAKDAxsf+U05IMPPiAANH78+A4tVyqVUrdu3Vocw1ddXS2MRVN37bWysjIaOHAgAU3rxOXk5LSn2s06cOAAASAXFxe5R5vXr18XlvwBQLa2tnLj3NT5Q0kdzXWcbN68WQg4R4wYofJaftrAgZ0WcGDH2NOjI8a/PnkTb89CrqWlpcJN8c6dO2qX0x6ynpmlS5e2uyzZwrRz587tgJppRnZ2ttCr2FGTX4iI0tPTCQBZWlq22FN05swZ4f+eKuM6jx07Rn369KHevXsTAHJ2dqbs7OyOqLpStbW1ZG1tTQDIw8ODEhMTacOGDcKEGysrK9qwYYNejqdNSkoS6jl06FB68OCBTurRHB5jxxhjHagjxr+KRKIOWfbkxIkTICL4+vqiW7duapfTHh05zk42vm7w4MHtLktT+vfvj2effRYNDQ344YcfOqzcn376CUDT77OlMW1BQUHCEihvvvkmiouLWy2biLBkyRLk5uYiLy8PXbt2xfHjx9G/f/+OqbwSZmZmGDduHACgoKAAkydPxltvvYWHDx8iLCwMly9fxptvvqmX42nDw8Nx/Phx2Nvb4+zZsxg2bBj27NmD/v37IykpSSd1UpexrivAGGP6TjZQv7S0VOGYs7Nzm29GISEhiI+Pb9cECtn6deHh4WqX0V6ywC4tLQ3l5eWwt7dXq5z6+nphXTFVJk7owowZM5CRkYG4uDhh3bn2OnLkCABgzJgxrZ67bNkyHD16FGlpaZgwYQJqa2vx5ZdfYsSIEZBKpSguLsb169eRl5eH69ev49SpU7h48aKQ/+OPP4avr2+H1LslT04AqaqqQpcuXbBq1SosWLBAmLjg6uoKV1dXjddFVUOGDEFycjJGjRqFzMxMvPrqq5BIJPjggw8QHh4u7POs9zTef2ig+FEsY0xVqampBIDs7OzUXl5BNt5K01svtaZv374EgPbt26d2GbJHkba2tnq/3MTt27eFR+A3b95sd3lPPlJv6+S4q1evCtucyf4f+fj4yG09qeylrSWzpFIpBQYGyv1sX1/fTrdUV15ensLj4qNHj+q0TvwoljHG9NCzzz4LS0tLVFRUICcnR+X8BQUFyM/Ph1gsRlhYmAZq2HYd8Tj23LlzAJoewypbhkKf9OzZE8OHDwcAuaU61PXzzz+DiODn5wcXF5c25fH29sZrr70mvK+oqEB2djZqa2shFovRq1cvREZGIioqSi6fVCrVyi4uiYmJcjs7AE3Lm3S23R28vLwUhjlER0cjPT1dRzVSjX5/kxhjzIAYGxsLjxzVeRwreww7ZMgQldbQ04QntxdT15OBXWcgW9Nux44d7V5zTfYYduzYsW3OQ0Q4d+6c8EhQJBKhd+/eyM3NRW1tLfLy8vDTTz+hpKREIVA2MjLS6Fpx1Mw6cZr+uZqQmJiIS5cuyaVVV1cjMDAQr7zyCgoLC3VUs7bhwI4xxrSoPQsVy4IoWVClS8OGDYNYLEZeXp7aNzp1FibWpZdeegmmpqbIyclBRkaG2uU0NjYiISEBQNvG18n8cT9lIkJeXh5u3LiBLl26ANDdQveGssB+cwGqzI4dO+Dt7Y0lS5agvLxcy7VrGw7sGGNMi9SdGSuVSoUeO30I7GxtbYWeNnV67aqqqoTH0Z0lsLO1tcX48eMBAHFxcWqXc+7cOTx48AD29vYYOnRom/K0tUdMV7u4dJbdY1rTXIAKAI6Ojhg2bBgkEglWr14NLy8vrFmzBkeOHNGr2bM8K5YxxrRo6NChMDIyws2bN1FSUoIePXq0Kd8333yD0tJSmJqa6k0gNGLECKSkpCApKUlu7FdbpKamgojg4eEBZ2dnDdWw402fPh3x8fHYtWsXPvvsM4jFYpXLkD2GHT16NIyN23YbbkuPmCx40tWsU32d7aqK1mbA9+zZEwkJCViyZAmysrKwePFimJiYoK6uDu+//75ezJ7lHjvGGNMia2tr+Pv7A2h7rx0R4V//+heAprXCZI/ddG3kyJEAmsb+KevhaIlsfJ2+BKltFRkZCTs7O5SUlCA5OVmtMmTr16nyGNZQesQ6A1dXVwQEBCi8XFxcIBKJEBkZiYyMDHz77bdwcHAQHjOnpaXpxUQRDuwYY0zLgoODAbR9nN3evXtRVFQEAKisrNSLmwfQFJRZWlqitLQUmZmZKuXtbBMnZExNTTFlyhQATeOtVFVcXIyMjAyIRCJERESolLelgINpl1gsxqxZs+Dh4SH00OnLRBEO7BhjTMtUmUAhkUgwe/Zs4b1YLNaLmwcAmJiYCMuuqDK+SDa7E+h8PXbA77Njd+/ejX79+qn02Y8ePQqgKaB1cnLSSP2YdiQmJiI9PV34LmprWZnWcGDHGGNaJuuxy8jIQHV1dbPnEREmTJggd05jY6Ne3Dxk1Fn2pKioCHfv3oWxsTECAgI0VTWNCQ0NhYuLCx49eoSrV6/igw8+aHOgrc4yJ0z/6PPyLhzYMcaYlrm4uMDd3R1SqVTouVJm1apVSgM4fbh5yMjG2f366694/Phxm/LIPrOfnx/Mzc01VjdNMTIyQlBQkPC+rYF2XV2dsKCzKuPrmP7R5+VdeFYsY4zpQEhICAoLC3H69Gmly5fs27cP//jHP5TmVTYTUld8fHzwzDPP4O7du0hJSRF2Z2hJZx1fJ0NEcjuHiEQifPjhhxg1alSLMyJPnjyJmpoadOvWDQMHDtRGVZmGdNT+0ZrAgR1jjOlAcHAw4uLilI6zS0tLw4wZMwAAMTExWLBggcI5ur55yIhEIowYMQJxcXFISkpSKbDrjOPrgKaxVVlZWcJ7IkJaWhp+/vnnFidEyB7DRkZG6v0Waqx1+rq8Cwd2jDGmA7IJFCkpKWhoaBDWM7t9+zYmTJiA2tpaREZG4ptvvmnzWme6MnLkSMTFxeHYsWP497//3eK5DQ0Nwo4TjY2N2qheh3pybNUfH8PNmTMHRUVFzfbaqbPMCWOq4j8ZGGNMB3x8fGBra4uHDx8KS4XU1NRg3LhxuHPnDnx9ffH999/rfVAHAOHh4QCaxpp5e3u3OJHi8uXLwvijjRs36sU4QVW0tDNBcXEx1q5dqzRffn4+rl27BmNjY2FcImOaoP9XDMYYM0BGRkZ4/vnncfToUZw6dQr+/v6YNm0aLl26BGdnZxw+fBg2Nja6rmabuLi4wNvbG9euXUNubi6mTp2KkJAQVFdXo6qqSu7fmpoaIZ9sQdfRo0frsPaqaW5s1ddff41NmzZh8eLFcHR0RExMjNxx2TInISEhsLW11Vp92dOHAzvGGNORkJAQHD16FMuWLUNycjIOHz4MMzMzHDx4EO7u7rqunkr69euHa9euAQDKysrw448/tppHtiZfa5MO9I2ysVUbN26EhYUF1q1bh9mzZ8Pa2hqTJk0Sjssew/IyJ0zT+FEsY4zpyPPPPw8AqKqqwr59+wAA27dv73STCogIBQUFQnAmEong7u6OHTt24NChQ0hOTkZ6ejq2bNkil0/f1uRrD5FIhNjYWMyaNQtSqRTTpk0TljZ59OgRTpw4AYDH1zHN4x47xhjTkcrKSrn3r776KqKjo3VUG/UlJiYiIyNDeE9EKCwsRNeuXYXHrESEv/71rwqTDmRr8nW2XjtljIyMsHnzZlRXVyM+Ph4TJ05EYmIiysvLIZFI4OHhgX79+um6mszAcWDHGGM6QERyM0hFIhGuXLkCIupUAU5zs0T/GLC1ZUFXfVi+pb3EYjHi4uJQU1ODhIQEjB07Fp6engCAAQMGdKq2ZZ0TB3aMMaYDiYmJSE1NFd7L1kLrbJMJ2hqw6fOCrh3NxMQEe/fuxejRo3Hq1ClcvHgRAHD16tVOF7izzkdEnW2uuZ6oqqqCra0tKisrO83MNcaYfiAiDBkyBBcuXFDo5QoMDMS5c+c61c2/qKio2YDNxcVFBzXSD5WVlRg0aBCuX78upCUkJHSqwJ3pB1ViDr2ePFFbW4uPPvoIffr0gZmZGXr06IHZs2ejuLhY5bLKy8uxcOFCuLu7w9TUFO7u7njnnXdQUVHR8RVnjLEW6PM+k+pwdXVFQECAwutpDuoAwMbGBlZWVkKQLpsFzP0pTJP0tsfu8ePHGD58OM6ePYvu3bsjNDQUBQUFOH/+PJycnHD27Flh3EJr7t+/j6CgIFy/fh2enp4YNGgQsrOzkZ2djT59+iAlJQUODg4q1Y977Bhj7cG9XIavuS3GuNeOqUqlmIP01NKlSwkABQUFUXV1tZAeGxtLACgsLKzNZU2fPp0A0KRJk6i+vl5If/vttwkAxcTEqFy/yspKAkCVlZUq52WMMWbYpFIpPffcc2RkZEQAhJeRkRE999xzJJVKdV1F1omoEnPoZY9dXV0dnJ2dUVlZifT0dAwcOFDuuL+/PzIzM5GWlobAwMAWy7pz5w5cXFxgbGyMW7du4ZlnnhGOSSQSuLq64sGDBygpKYGzs3Ob68g9dowxxpojkUjg7u6Ou3fvKhzr1q0bCgoKDGrCCNOsTj/G7vTp06isrISXl5dCUAcAkydPBgAcOnSo1bISEhIglUoRGhoqF9QBTVvDjB8/Ho2NjThy5EjHVJ4xxthTTzYL+MKFCwqv1NRUDuqYxujlcieXLl0CAAQEBCg9LkuXbZzd3rK2bNnSprIYY4yxtlK29RhjmqaXPXa3bt0CgGYHEMvSCwsLtVoWY4wxxpg+08seu5qaGgCAhYWF0uOWlpYAgOrqaq2VJZFIIJFIhPdVVVWt/mzGGGOMMW3Syx47ffTJJ5/A1tZWeHH3OmOMMcb0jV4GdlZWVgCAR48eKT3+8OFDAIC1tbXWynr//fdRWVkpvIqKilr92Ywxxhhj2qSXj2Ld3NwAALdv31Z6XJbu7u6utbJkex0yxhhjjOkrveyx8/f3BwCkp6crPS5L9/Pz02pZjDHGGGP6TC8Du+DgYNja2iI/Px8ZGRkKx+Pj4wEA48ePb7WsiIgIGBkZ4eTJk7h3757cMYlEgkOHDkEsFmPMmDEdUnfGGGOMMV3Ry8DOxMQE8+fPBwDMmzdPGAcHAGvWrEFmZibCwsLkdp34z3/+g759++L999+XK6t79+6YNm0a6urqMHfuXDQ0NAjHlixZgtLSUsyYMUOlXScYY4wxxvSRXo6xA4APP/wQSUlJOHPmDHr37o3Q0FAUFhbi3LlzcHJywpYtW+TOv3//Pq5du4Y7d+4olLVu3TqcPXsWe/fuRd++fTFo0CBkZ2cjKysLvXv3xpo1a7T1sRhjjDHGNEYve+wAwMzMDCdOnMCyZctgYWGBAwcOoLCwEDNnzkR6ejo8PT3bXFbXrl1x/vx5vP3226irq8P+/ftRWVmJBQsW4Pz583BwcNDgJ2GMMcYY0w4REZGuK9EZqbIhL2OMMcaYulSJOfT2Uay+k8XDvAMFY4wxxjRJFmu0pS+OAzs1ybYg4x0oGGOMMaYN1dXVsLW1bfEcfhSrJqlUipKSElhbW0MkErU5X1VVFVxdXVFUVMSPcPUEt4l+4fbQL9we+ofbRL9ooz2ICNXV1ejRoweMjFqeHsE9dmoyMjKCi4uL2vltbGz4C6lnuE30C7eHfuH20D/cJvpF0+3RWk+djN7OimWMMcYYY6rhwI4xxhhjzEBwYKdlpqamWL58OUxNTXVdFfb/uE30C7eHfuH20D/cJvpF39qDJ08wxhhjjBkI7rFjjDHGGDMQHNgxxhhjjBkIDuy0pLa2Fh999BH69OkDMzMz9OjRA7Nnz0ZxcbGuq2aQHj16hAMHDuC1116Dt7c3zMzMYGlpCX9/f6xcuRI1NTXN5t22bRsGDx4MKysrODg4YMyYMThz5owWa/90KCsrg7OzM0QiEXr16tXiudwmmlVaWop3330X3t7eMDc3h4ODAwICAvDee+8pPf/QoUMICwsTlncYNmwYfvrpJy3X2jClpqYiOjoaPXr0QJcuXWBnZ4fQ0FBs3bpV6a4DjY2NWLt2LQYMGABzc3M4OTkhOjoaOTk5Oqh953ThwgV8+umnmDRpElxcXCASidq0Pq0616XTp09jzJgxcHBwgJWVFQYPHozvvvuuoz5KE2IaV1tbS0OHDiUA1L17d4qOjqbBgwcTAHJycqL8/HxdV9HgbN68mQAQAOrXrx9NmTKFRo8eTdbW1gSA+vbtS3fv3lXIt3DhQgJA5ubmFBUVRaNHjyZjY2MSi8W0f/9+7X8QAxYTE0MikYgAkJeXV7PncZtoVlpaGjk6OhIA8vHxob/85S8UGRlJ7u7uJBaLFc5fu3YtASBjY2OKiIigqKgoMjc3JwD01Vdf6eATGI74+HgSi8UEgAICAig6OpqGDx9OxsbGBIBefvllufMbGxvpxRdfJABkZ2dHL730EoWFhZFIJCILCws6d+6cjj5J5xIVFSXcL558tUSd65KsfUUiEYWFhdFLL71EdnZ2BIAWL17cYZ+HAzstWLp0KQGgoKAgqq6uFtJjY2MJAIWFhemucgZq27Zt9MYbb9CVK1fk0ktKSmjgwIEEgKZNmyZ37NixYwSAHB0dKTc3V0g/c+YMmZiYkJ2dHZWXl2uj+gYvKSmJANAbb7zRYmDHbaJZ9+7do65du5KFhQX9+OOPCsf/GBhcvXqVxGIxmZqa0pkzZ4T0a9eukaOjIxkbG1NeXp7G622I6uvrydnZmQBQXFyc3LErV66Qg4MDAaBffvlFSJf9Adu7d2/67bffhPT4+HgCQL169aL6+nqtfYbO6tNPP6Vly5bRwYMH6c6dO2RqatpiYKfOdamsrIxsbGwIAO3du1dI/+2336hXr14EgE6cONEhn4cDOw2TSCRka2tLACg9PV3huJ+fHwGgtLQ0HdTu6XTmzBkCQKampiSRSIT0yMhIAkBr165VyLNgwQICQJ9//rkWa2qYHj16RF5eXtS/f3/Kzc1tMbDjNtGst956iwDQ+vXrVTp/4cKFCsfWrFlDAGj+/PkdXMunw+XLlwkAeXt7Kz0u+//+2WefCWn9+vUjAEp7iCZMmEAAKD4+XlNVNlitBXbqXJc+++wzAkBRUVEKefbt20cAaNy4ce2tOhER8Rg7DTt9+jQqKyvh5eWFgQMHKhyfPHkygKYxK0w7/P39AQASiQRlZWUAmsZA/vLLLwB+b5MncTt1nBUrVuDGjRvYuHEjunTp0ux53CaaVVtbix07dsDS0hKzZs1qUx7ZODpuj47X1jXQHB0dAQA3b95ETk4OzM3NMXbsWIXzuD00Q93rUkvfnbFjx8LMzAxJSUl4/Phxu+vIgZ2GXbp0CQAQEBCg9LgsPTMzU2t1etrduHEDANClSxc4ODgAAK5duwaJRAInJyelewBzO3WMzMxMxMbGYtasWQgNDW3xXG4TzUpLS0N1dTUGDhwIc3NzHD16FIsWLcLcuXOxbt06lJSUyJ1fUVGBW7duAYDSP1JdXV3RtWtXFBYWoqqqSiufwZB4enrCy8sL165dw86dO+WO5eTkYMeOHbC3t8eLL74I4Pd7i6+vr9I/kPj7oRnqXpdaigVMTEzg6+uLx48fIzc3t9115MBOw2QXQmX/AZ5MLyws1FqdnnZffPEFACAiIkL4K7m1drK0tISdnR3Ky8tRXV2tnYoaGKlUijlz5sDOzg6rVq1q9XxuE826cuUKAMDZ2RkTJ07EmDFjsHbtWmzYsAF/+9vf0KtXL+zatUs4X9Ye9vb2sLS0VFomX8/UJxaLsX37dtjZ2WH69OkIDAzE1KlT8cILL8DPzw8uLi44fvy48Mco31t0Q53rUlVVFSorK1vM15HtxYGdhsmW1bCwsFB6XHaB5BuTdhw5cgTffvstunTpgo8//lhIb62dAG6r9vrqq6+QmpqK1atXC4+TWsJtolnl5eUAgIMHDyIhIQHr16/HvXv3UFBQgHfffRe1tbWIiYlBRkYGAG4PbQgODkZycjI8PT2Rnp6O3bt348SJEzAyMsLIkSPh6ekpnMv3Ft1Q53vw5PJa2mgvDuzYU+Pq1auYMWMGiAirV68Wxtoxzbt16xY+/PBDhIWFYebMmbquDkNTDyoANDQ0YOXKlZg7dy6cnJzg7u6O1atXY8qUKaivr8fq1at1XNOnx65duzB48GC4urri3LlzqKmpQW5uLmbOnInY2Fi88MILkEgkuq4m03Mc2GmYlZUVgKYFc5V5+PAhAMDa2lprdXoaFRcXIyIiAuXl5Vi0aBEWLlwod7y1dgK4rdpj3rx5qKurw8aNG9uch9tEs2S/XwBKJ0/I0pKTk+XO5/bQjLy8PMTExKBr1644fPgwBg8eDEtLS/Tu3Rtff/01xo0bh/T0dGzZsgUA31t0RZ3vwZPfNW20Fwd2Gubm5gYAuH37ttLjsnR3d3et1elp8+DBA4waNQqFhYWYNWsWPv/8c4VzWmunhw8foqKiAvb29nyhVMPhw4dhYWGBN998E8OGDRNeU6dOBdAUeMvSfvvtNwDcJpomu+ZYWFjAyclJ4biHhwcA4N69ewB+b4/y8nLhJvRHfD1T3/fff4/6+npERETIBQIy0dHRAIBff/0VAN9bdEWd65KNjQ1sbW1bzNeR7WXc7hJYi2SP+9LT05Uel6X7+flprU5Pk5qaGkRGRuLKlSuYNGkSNm/erHSrGG9vb5iamqK0tBTFxcXo2bOn3HFup/arqKgQen/+6PHjx8Ix2XR/bhPNks1sra2thUQiUVhu48GDBwB+722ws7ODm5sbbt26hYsXLyIkJETu/KKiIty/fx/u7u6wsbHRwicwLLIbuywA+CNZumxspOzekpWVhfr6eoWZsfz90Ax1r0v+/v749ddfkZ6ejv79+8sdq6+vR1ZWFszMzNCnT59215F77DQsODgYtra2yM/PFwYhPyk+Ph4AMH78eC3XzPBJJBJERUXh/PnzGD16NHbt2gWxWKz0XHNzc7zwwgsAgB9++EHhOLdT+1DTYugKr5s3bwIAvLy8hDRZTxG3iWa5ubnB398fRKQ04JalPbm0iWy9NNnv/kncHu3TrVs3AE3L0CiTmpoK4Pee1D/96U/o168famtrle7Ty+2hGepel1r67hw+fBiPHz/GiBEjYGZm1v5Kdsgyx6xFsi3Fnn/+eaqpqRHSeUsxzWloaBD2UAwNDaWHDx+2mqelbWJMTU15+yoNuHnzptpbinGbtF9cXBwBoAEDBlBJSYmQfvHiRWELqz179gjpT24plpKSIqTn5ubylmLtdOHCBWGP0v/+979yx1JSUsjS0pIA0LFjx4T0J7cUe3Lv67179/KWYu3Qni3FmrsuNbel2N27d3lLsc6otraWhgwZQgCoe/fuFB0dLbx3cnKi/Px8XVfR4Kxbt064SL744osUExOj9FVaWiqXT7axs4WFBUVFRVFkZCRvOK9BrQV2RNwmmhYTEyNsIj9mzBgaPny4cGN7/fXXFc6XbR1mbGxMkZGRFBUVRebm5gSAvvzySx18AsPx7rvvCtctHx8fmjJlCgUHB5ORkZGwt/KTGhsbhT9g7e3tafLkyTRs2DASiURkbm5OZ8+e1dEn6VwOHz5MQ4YMEV4ikYgAyKUdPnxYLo8616X4+HgyMjIikUhEw4cPp8mTJ5OdnR0BoEWLFnXY5+HATksePXpEy5YtIy8vLzIxMaFu3brRzJkzqaioSNdVM0jLly8XLpAtvW7evKmQd+vWrRQYGEgWFhZkZ2dHERERdPr0ae1/iKdAWwI7Im4TTZJKpbRp0ybh92tpaUlBQUG0bdu2ZvMcPHiQQkNDycrKiqysrCg0NJQOHTqkxVobrn379tGoUaOEHlB7e3saPnw47dy5U+n5DQ0NFBsbSz4+PmRmZkaOjo40efJkys7O1nLNO6+tW7e2eq/YunWr0nyqXpdOnTpFERERZGdnRxYWFjRo0KAWv2vqEBERtf+BLmOMMcYY0zWePMEYY4wxZiA4sGOMMcYYMxAc2DHGGGOMGQgO7BhjjDHGDAQHdowxxhhjBoIDO8YYY4wxA8GBHWOMMcaYgeDAjjHGGGPMQHBgxxhjjDFmIDiwY4wZPJFI1Opr5syZuq5mq/75z39CJBJh27Ztuq4KY0xPGeu6Aowxpi0xMTHNHgsJCdFiTRhjTDM4sGOMPTW4p4sxZuj4USxjjDHGmIHgwI4xxpQQiUTw8PBAXV0dli9fDi8vL5iZmcHT0xMfffQRHj9+rDRfWVkZ3nvvPfTu3RtmZmZwcHBAREQEEhMTm/1ZZWVlWLp0KQYMGABLS0vY2NhgwIABWLJkCe7cuaM0z+XLlzFhwgTY29vD0tISYWFhOHPmjNJzjxw5gpEjR6Jnz54wNTVFjx49EBISghUrVqj+i2GM6TUREZGuK8EYY5okEokAAKpc7kQiEdzc3ODn54fjx48jPDwcJiYmOH78OCorKxEeHo6ff/4ZYrFYyFNcXIw///nPuHHjBtzc3BAUFITS0lIkJyejsbERa9aswd/+9je5n5OTk4NRo0bh9u3b6NatG4KCggAAubm5yM7Oxv79+zFx4kQATZMnVqxYgXnz5mHr1q3w8vJC//79cfXqVVy6dAlmZmZITU2Fr6+vUP769esxf/58iMViBAcHo2fPnrh//z5ycnJw+/ZtlX4njLFOgBhjzMABIFUvd7I8Li4ulJ+fL6Tfu3ePfH19CQCtXbtWLs+4ceMIAL388sskkUiE9JMnT5KFhQWJxWK6ePGikF5fX0/e3t4EgN555x25PEREWVlZdP36deH98uXLhXp98cUXcue+8847BIBeeeUVuXQ3NzcSiUSUmpoqly6VSunEiROq/EoYY50AB3aMMYMnC4Zaeu3fv19pnk2bNimUd/ToUQJAXl5eQlp+fj4BICsrKyorK1PIs2jRIgJAc+bMEdJ2795NAMjHx4caGhpa/RyywC44OFjh2P379wkAubu7y6Wbm5uTvb19q2UzxgwDz4pljD01WlruxM3NTWn61KlTFdIiIiJgb2+P/Px83LlzB927d8epU6eEYw4ODgp5XnnlFaxZswYnT54U0pKSkgAAc+bMkXuk25pRo0YppDk6OsLBwUFhTF5gYCBOnTqF1157DYsWLYKPj0+bfw5jrPPhwI4x9tRQdbkTe3t7WFtbKz3m7u6O8vJylJSUoHv37igpKQEAeHh4KD1fll5cXCykFRUVAQC8vLxUqpeLi4vSdGtrazx48EAubf369Zg4cSK2bNmCLVu24JlnnkFYWBgmTZqEyZMnqxRQMsb0H8+KZYwxLZBN4OgIRkZtv3T7+fnhypUr2L9/P15//XXY2Nhgz549mDp1KkJDQ1FXV9dh9WKM6R4Hdowx1ozy8nJUV1crPXbr1i0AQI8ePeT+LSwsVHp+QUEBAKBnz55CmqurKwAgPz+/Q+rbHDMzM0ycOBGbNm1Cbm4usrKy4Ofnh5SUFHzzzTca/dmMMe3iwI4xxlqwZ88ehbTExEQ8ePAAnp6e6N69O4DftyRLSEhARUWFQp4dO3YAAEJDQ4W0ESNGAAC+/fZbSKXSjq56s3x8fDBv3jwAQFZWltZ+LmNM8ziwY4yxFqxYsULobQOA+/fv47333gMAITgCAE9PT4wdOxbV1dVYuHAh6uvrhWMpKSnYsGEDxGKxXJ5JkyahT58+yMrKwpIlS+TyAEB2djZu3Lihdt0fPXqEL7/8UiHQlEqlSEhIAPB7ryFjzDDw5AnG2FNj5syZzR5zc3PDypUrFdL8/Pzg4+OD8PBwdOnSBb/88gsqKiowfPhwLFiwQO78r7/+GqGhofjuu++QnJwsLFD8v//9D42NjYiNjcWzzz4rnG9sbIy9e/di5MiRiI2Nxc6dOxEUFAQiQl5eHrKysrB//354enqq9Xnr6uqwcOFCvPvuuwgMDBR20khNTUVRURE8PDzwxhtvqFU2Y0w/cWDHGHtqbN++vdlj/v7+CoGdSCRCfHw8Vq5ciZ07dwozYOfNm4elS5fC2Fj+EtqzZ0+kpqbik08+wYEDB7Bv3z5YWFggPDwcixcvVrpMia+vLy5duoTVq1fj4MGDOHLkCExNTeHm5oa///3vGDp0qNqf18rKCuvXr8fx48dx6dIlZGZmwsTEBG5ubpgzZw7mz5+vdGkWxljnxVuKMcaYEiKRCO7u7nKPYRljTN/xGDvGGGOMMQPBgR1jjDHGmIHgwI4xxhhjzEDw5AnGGFOChx8zxjoj7rFjjDHGGDMQHNgxxhhjjBkIDuwYY4wxxgwEB3aMMcYYYwaCAzvGGGOMMQPBgR1jjDHGmIHgwI4xxhhjzEBwYMcYY4wxZiA4sGOMMcYYMxD/B8HmFGRfiItQAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_ticks3 = [i * 2 for i in range(1, len(proposed_acc128_50[0][::2]) + 1)]\n",
    "\n",
    "plt.plot(x_ticks3, proposed_acc128_50[0][::2], label='Proposed', color='orange', linestyle='-', marker='o', markersize=4)\n",
    "plt.plot(x_ticks3, xavier_acc128_50[0][::2], label='Xavier', color='blue', linestyle='-', marker='D', markersize=4)  \n",
    "plt.plot(x_ticks3, orthogonal_acc128_50[0][::2], label='Orthogonal', color='brown', linestyle='-', marker='s', markersize=4)  \n",
    "plt.plot(x_ticks3, hebatch_acc128_50[0][::2], label='He + BN', color='black', linestyle='-', marker='^', markersize=4)  \n",
    "plt.legend(fontsize= 13)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Epochs\", fontsize=15)\n",
    "plt.ylabel(\"Validation Accuracy\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig('C_initialization.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984b38eb-233c-428d-ad11-33592b18e6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
